{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Digit Classification with KNN and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll implement your own image recognition system for classifying digits. Read through the code and the instructions carefully and add your own code where indicated. Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n",
    "\n",
    "As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but <b> please prepare your own write-up (with your own code). </b>\n",
    "\n",
    "If you're interested, check out these links related to digit recognition:\n",
    "\n",
    "Yann Lecun's MNIST benchmarks: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Stanford Streetview research and data: http://ufldl.stanford.edu/housenumbers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jennifer\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Jennifer\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data. Notice that we are splitting the data into training, development, and test. We also have a small subset of the training data called mini_train_data and mini_train_labels that you should use in all the experiments below, unless otherwise noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (70000L, 784L)\n",
      "label shape: (70000L,)\n"
     ]
    }
   ],
   "source": [
    "# Load the digit data either from mldata.org, or once downloaded to data_home, from disk. The data is about 53MB so this cell\n",
    "# should take a while the first time your run it.\n",
    "mnist = fetch_mldata('MNIST original', data_home='~/datasets/mnist')\n",
    "X, Y = mnist.data, mnist.target\n",
    "\n",
    "# Rescale grayscale values to [0,1].\n",
    "X = X / 255.0\n",
    "\n",
    "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n",
    "# permutation to X and Y.\n",
    "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print 'data shape: ', X.shape\n",
    "print 'label shape:', Y.shape\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "test_data, test_labels = X[61000:], Y[61000:]\n",
    "dev_data, dev_labels = X[60000:61000], Y[60000:61000]\n",
    "train_data, train_labels = X[:60000], Y[:60000]\n",
    "mini_train_data, mini_train_labels = X[:1000], Y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Create a 10x10 grid to visualize 10 examples of each digit. Python hints:\n",
    "\n",
    "- plt.rc() for setting the colormap, for example to black and white\n",
    "- plt.subplot() for creating subplots\n",
    "- plt.imshow() for rendering a matrix\n",
    "- np.array.reshape() for reshaping a 1D feature vector into a 2D matrix (for rendering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAJCCAYAAAALCSnoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhMQCKcMwDMMwjJBYIGUYhmEYhhGS/wdW1WRhZWrXVAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1054ce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def P1(num_examples=10):#set the number of pics to show for each digit\n",
    "\n",
    "### STUDENT START ###\n",
    "    #set the range of digits of interest (ex: 3 for digit 0:2)\n",
    "    digits = 10\n",
    "\n",
    "    #Create matrix that holds the position of each digit within the mini_train dataset\n",
    "    df = []\n",
    "    for j in range(digits):\n",
    "        list_digit_index =[] #holds values of position of label\n",
    "        x=0 #counts the place in the label array\n",
    "        #iterates over list of all labels, until the correct number of examples is filled\n",
    "        while len(list_digit_index)<num_examples: \n",
    "            #checks to see if the digit is the one we are looking for\n",
    "            if(mini_train_labels[x]==j): \n",
    "                #documents the np location (of the image data) in a list\n",
    "                list_digit_index.append(x)\n",
    "            x+=1  #moves on to the next value in the total list of labels\n",
    "        df.append(list_digit_index) #combines the location data for each digit into 1 place\n",
    "    #converts list of lists into matrix using np\n",
    "    df2 = np.array(df)\n",
    "\n",
    "    #set up flexible grid of images and adjusts the size of the images\n",
    "    fig, axes = plt.subplots(digits,num_examples,figsize=(10,10))\n",
    "    #fill in the grid \n",
    "    for k in range(digits):\n",
    "        for i in range(1, num_examples +1):\n",
    "            #data index location\n",
    "            position = df2[k,(i-1)]\n",
    "            #select the data for one image & convert 1D array into 2DMatrix\n",
    "            image_i_data = np.reshape(mini_train_data[position,], (28, 28))\n",
    "            #Show the image of the one number and converts the image to black and white\n",
    "            axes[k,i-1].imshow(image_i_data,cmap='gray_r')\n",
    "            #remove annoying tick marks on x & y axis\n",
    "            axes[k,i-1].axis('off')\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "P1(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Evaluate a K-Nearest-Neighbors model with k = [1,3,5,7,9] using the mini training set. Report accuracy on the dev set. For k=1, show precision, recall, and F1 for each label. Which is the most difficult digit?\n",
    "\n",
    "- KNeighborsClassifier() for fitting and predicting\n",
    "- classification_report() for producing precision, recall, F1 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter k:1  number of incorrect predictions: 112  Accuracy Rate 88.8%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.98      0.94        99\n",
      "        1.0       0.89      1.00      0.94       105\n",
      "        2.0       0.99      0.79      0.88       102\n",
      "        3.0       0.77      0.87      0.82        86\n",
      "        4.0       0.89      0.82      0.85       104\n",
      "        5.0       0.93      0.84      0.88        91\n",
      "        6.0       0.94      0.96      0.95        98\n",
      "        7.0       0.89      0.92      0.90       113\n",
      "        8.0       0.94      0.88      0.91        96\n",
      "        9.0       0.78      0.82      0.80       106\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1000\n",
      "\n",
      "Hyperparameter k:3  number of incorrect predictions: 122  Accuracy Rate 87.8%\n",
      "Hyperparameter k:5  number of incorrect predictions: 131  Accuracy Rate 86.9%\n",
      "Hyperparameter k:7  number of incorrect predictions: 135  Accuracy Rate 86.5%\n",
      "Hyperparameter k:9  number of incorrect predictions: 137  Accuracy Rate 86.3%\n"
     ]
    }
   ],
   "source": [
    "def P2(k_values):\n",
    "\n",
    "    ### STUDENT START ###\n",
    "    dev_accuracy = []\n",
    "    #try out some different k here\n",
    "    for k in (k_values):\n",
    "        #builds model\n",
    "        model = KNeighborsClassifier(n_neighbors=k)\n",
    "        model.fit(mini_train_data, mini_train_labels)\n",
    "        #makes predictions on the dev dataset with the model we just built\n",
    "        test_predicted_labels = model.predict(dev_data)\n",
    "\n",
    "        #accuracy Calcs\n",
    "        wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "        print \"Hyperparameter k:\" + str(k),\n",
    "        print ' number of incorrect predictions:', np.sum(wrong_prediction), \n",
    "        accuracy_rate = np.sum((test_predicted_labels == dev_labels))/float(len(dev_labels))*100\n",
    "        print ' Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "        if k ==1:\n",
    "            print classification_report(dev_labels,test_predicted_labels)\n",
    "### STUDENT END ###\n",
    "\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "P2(k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: overall digit 9 is the most difficult as shown by the lowest f1 score. Digit 3 the model only recognizes 77% of the time and digit 2 the model thinks its a 2, but its not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Using k=1, report dev set accuracy for the training set sizes below. Also, measure the amount of time needed for prediction with each training size.\n",
    "\n",
    "- time.time() gives a wall clock value you can use for timing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sample Size:100  Accuracy Rate 70.9% 00:00:00\n",
      "Training Sample Size:200  Accuracy Rate 76.6% 00:00:00\n",
      "Training Sample Size:400  Accuracy Rate 83.8% 00:00:00\n",
      "Training Sample Size:800  Accuracy Rate 87.1% 00:00:00\n",
      "Training Sample Size:1600  Accuracy Rate 91.6% 00:00:01\n",
      "Training Sample Size:3200  Accuracy Rate 92.5% 00:00:03\n",
      "Training Sample Size:6400  Accuracy Rate 93.6% 00:00:07\n",
      "Training Sample Size:12800  Accuracy Rate 96.0% 00:00:15\n",
      "Training Sample Size:25000  Accuracy Rate 96.9% 00:00:46\n",
      "[70.899999999999991, 76.599999999999994, 83.799999999999997, 87.099999999999994, 91.600000000000009, 92.5, 93.600000000000009, 96.0, 96.899999999999991]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-207442f9d2e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mP3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[0mtime_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'time_list' is not defined"
     ]
    }
   ],
   "source": [
    "def P3(train_sizes, accuracies):\n",
    "\n",
    "### STUDENT START ###\n",
    "    #store the model run time here\n",
    "    time_list = []\n",
    "    #iterate over different train dataset sizes\n",
    "    for t_size in (train_sizes):\n",
    "        #subset the train data/labels dataset to the desired level\n",
    "        idx = np.random.choice(np.arange(len(train_data)), t_size, replace=False)\n",
    "        sample_train_data = train_data[idx]\n",
    "        sample_train_labels = train_labels[idx]\n",
    "\n",
    "        #starts the timer\n",
    "        start_time = time.time()\n",
    "\n",
    "        #builds model\n",
    "        model = KNeighborsClassifier(n_neighbors=1)\n",
    "        model.fit(sample_train_data, sample_train_labels)\n",
    "        #makes predictions on the dev dataset with the model we just built\n",
    "        test_predicted_labels = model.predict(dev_data)\n",
    "\n",
    "        #ends the timer\n",
    "        end_time = time.time()\n",
    "\n",
    "        #accuracy Calcs\n",
    "        wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "        print \"Training Sample Size:\" + str(t_size), \n",
    "        accuracy_rate = (np.sum((test_predicted_labels == dev_labels))/float(len(dev_labels))*100)\n",
    "        accuracies.append(accuracy_rate)\n",
    "        print ' Accuracy Rate '+  \"{0:.1f}%\".format(accuracy_rate), \n",
    "        run_time = time.strftime(\"%H:%M:%S\",time.gmtime(end_time - start_time))\n",
    "        print run_time\n",
    "        time_list.append(run_time)\n",
    "\n",
    "### STUDENT END ###\n",
    "train_sizes = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 25000]\n",
    "accuracies = []\n",
    "P3(train_sizes, accuracies)\n",
    "print accuracies\n",
    "print time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2017, tm_mon=9, tm_mday=24, tm_hour=18, tm_min=11, tm_sec=31, tm_wday=6, tm_yday=267, tm_isdst=0)\n",
      "11:31\n"
     ]
    }
   ],
   "source": [
    "#start_time2 = time.time()\n",
    "print time.gmtime(start_time2)\n",
    "print (time.strftime(\"%M:%S\",time.gmtime(start_time2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-7e012b4b9650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'time'"
     ]
    }
   ],
   "source": [
    "print time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Fit a regression model that predicts accuracy from training size. What does it predict for n=60000? What's wrong with using regression here? Can you apply a transformation that makes the predictions more reasonable?\n",
    "\n",
    "- Remember that the sklearn fit() functions take an input matrix X and output vector Y. So each input example in X is a vector, even if it contains only a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction with all datapoints and no transformation:[ 125.02525591]\n",
      "Prediction with all datapoints and transformation data:[ 106.18722544]\n"
     ]
    }
   ],
   "source": [
    "def P4(train_sizes, accuracies):\n",
    "    \n",
    "### STUDENT START ###\n",
    "    #creating/formatting the data\n",
    "    regression_train_data = np.array(train_sizes).reshape((len(train_sizes),1))\n",
    "    regression_train_labels = np.array(accuracies) \n",
    "    \n",
    "    #build the regression model\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(regression_train_data,regression_train_labels) \n",
    "\n",
    "    print 'Prediction with all datapoints and no transformation:'+ str(reg.predict(60000))\n",
    "    \n",
    "    #applying transformation to enhance the model\n",
    "    trans_train_sizes = np.log10(train_sizes)\n",
    "    trans_accuracies = np.log10(accuracies)\n",
    "    trans_reg_train_data = np.array(trans_train_sizes).reshape((len(trans_train_sizes),1))\n",
    "    trans_reg_train_labels = np.array(trans_accuracies) \n",
    "    #print trans_reg_train_labels\n",
    "    \n",
    "    #build the regression model\n",
    "    reg2 = LinearRegression()\n",
    "    reg2.fit(trans_reg_train_data, trans_reg_train_labels) \n",
    "    \n",
    "    #transformed prediction\n",
    "    trans_pred = reg2.predict(np.log10(60000))\n",
    "    #print trans_pred\n",
    "    transformedPred = 10**trans_pred\n",
    "    \n",
    "    print 'Prediction with all datapoints and transformation data:' + str(transformedPred)\n",
    "\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "P4(train_sizes, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: with a sample size of 60k (or all of the training data) the linear model predicts an accuracy of 126%, which is obviously wrong. The effect of adding more data is not linear; there are diminishing returns. From w203, we learned some potential transformations for could include taking the sqrt, taking the log or taking the log log (percent change in x and y). I applied the last technique, loglog and the transformation resulted an improved accuracy rate of 106%, which is still to high, but much closer to the goal of 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a 1-NN and output a confusion matrix for the dev data. Use the confusion matrix to identify the most confused pair of digits, and display a few example mistakes.\n",
    "\n",
    "- confusion_matrix() produces a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix for KNN model with k=1\n",
      "[[ 97   0   0   0   0   0   2   0   0   0]\n",
      " [  0 105   0   0   0   0   0   0   0   0]\n",
      " [  4   4  81   4   0   0   0   4   3   2]\n",
      " [  1   0   0  75   0   3   0   3   1   3]\n",
      " [  0   2   0   0  85   0   3   0   0  14]\n",
      " [  2   0   0   9   0  76   0   1   1   2]\n",
      " [  1   1   1   0   1   0  94   0   0   0]\n",
      " [  1   4   0   1   1   0   0 104   0   2]\n",
      " [  0   2   0   5   0   2   1   0  84   2]\n",
      " [  1   0   0   3   9   1   0   5   0  87]]\n",
      "Frequency of unique values of the incorrect predictions:\n",
      "[[  0.   2.   3.   4.   5.   6.   7.   8.   9.]\n",
      " [  2.  21.  11.  19.  15.   4.   9.  12.  19.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAGbCAYAAADgEhWsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVFBMAQBU+H+FaStu+hmqEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121ff518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#def P5():\n",
    "\n",
    "### STUDENT START ###\n",
    "#builds model\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(mini_train_data, mini_train_labels)\n",
    "#makes predictions on the dev dataset with the model we just built\n",
    "test_predicted_labels = model.predict(dev_data)\n",
    "\n",
    "#detailed review of accuracy prediction\n",
    "solution = confusion_matrix(dev_labels, test_predicted_labels)\n",
    "print 'confusion matrix for KNN model with k=1' \n",
    "print solution\n",
    "#find examples where the prediction doesn't match the label\n",
    "ix = (dev_labels != test_predicted_labels)\n",
    "\n",
    "#filter train/test to just the incorrect predictions\n",
    "key_train_index = np.where(ix) #finds position\n",
    "key_dev_data = dev_data[key_train_index] #filters data\n",
    "key_dev_labels = dev_labels[key_train_index] #filters labels\n",
    "key_test_pred_labels = test_predicted_labels[key_train_index] #filters predictions\n",
    "\n",
    "#key digits of interest (most incorrect)\n",
    "unique_elements, counts_elements = np.unique(key_dev_labels, return_counts=True)\n",
    "print(\"Frequency of unique values of the incorrect predictions:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "#we most often confuse 9's,4's and we are also bad at classifying 2's in general, \n",
    "#but those get predicted as a bunch of different things\n",
    "incorrect_digits_4 = [4,9]\n",
    "#isolating the data from a few examples that we got wrong\n",
    "ix = np.isin(key_dev_labels, incorrect_digits) #makes boolean\n",
    "#filter train/test to just the digits of interest\n",
    "incorrect_train_index = np.where(ix) #finds position\n",
    "incorrect_train_data = key_dev_data[incorrect_train_index] #filters data\n",
    "incorrect_train_labels = key_dev_labels[incorrect_train_index] #filters labels\n",
    "incorrect_test_predictions = key_test_pred_labels[incorrect_train_index]#filters predictions\n",
    "\n",
    "#Print some examples\n",
    "#Create matrix that holds the position of each digit within the incorrect_train_data\n",
    "df = []\n",
    "for j in (incorrect_digits):\n",
    "    list_digit_index =[] #holds values of position of label\n",
    "    x=0 #counts the place in the label array\n",
    "    #iterates over list of all labels, until the correct number of examples is filled\n",
    "    while len(list_digit_index)<6: \n",
    "        #checks to see if the digit is the one we are looking for\n",
    "        if((incorrect_train_labels[x]==j) & ((incorrect_test_predictions[x]==4) or (incorrect_test_predictions[x]==9))): \n",
    "            #documents the np location (of the image data) in a list\n",
    "            list_digit_index.append(x)\n",
    "        x+=1  #moves on to the next value in the total list of labels\n",
    "    df.append(list_digit_index) #combines the location data for each digit into 1 place\n",
    "#converts list of lists into matrix using np\n",
    "df2 = np.array(df)\n",
    "\n",
    "#set up flexible grid of images and adjusts the size of the images\n",
    "fig, axes = plt.subplots(2,6,figsize=(10,10))\n",
    "#fill in the grid \n",
    "for k in (0,1):\n",
    "    for i in range(1, 6+1):\n",
    "        #data index location\n",
    "        position = df2[k,(i-1)]\n",
    "        #select the data for one image & convert 1D array into 2DMatrix\n",
    "        image_i_data = np.reshape(incorrect_train_data[position,], (28, 28))#incorrect_train_data[position,]\n",
    "        #Show the image of the one number and converts the image to black and white\n",
    "        axes[k,i-1].imshow(image_i_data,cmap='gray_r')\n",
    "        #remove annoying tick marks on x & y axis\n",
    "        axes[k,i-1].axis('off')\n",
    "    \n",
    "### STUDENT END ###\n",
    "\n",
    "#P5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) A common image processing technique is to smooth an image by blurring. The idea is that the value of a particular pixel is estimated as the weighted combination of the original value and the values around it. Typically, the blurring is Gaussian -- that is, the weight of a pixel's influence is determined by a Gaussian function over the distance to the relevant pixel.\n",
    "\n",
    "Implement a simplified Gaussian blur by just using the 8 neighboring pixels: the smoothed value of a pixel is a weighted combination of the original value and the 8 neighboring values. Try applying your blur filter in 3 ways:\n",
    "- preprocess the training data but not the dev data\n",
    "- preprocess the dev data but not the training data\n",
    "- preprocess both training and dev data\n",
    "\n",
    "Note that there are Guassian blur filters available, for example in scipy.ndimage.filters. You're welcome to experiment with those, but you are likely to get the best results with the simplified version I described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Model (no blur):  number of incorrect predictions: 112  Accuracy Rate 88.8%\n",
      "Train Blur Model:  number of incorrect predictions: 91  Accuracy Rate 90.9%\n",
      "Dev Blur Model:  number of incorrect predictions: 129  Accuracy Rate 87.1%\n",
      "Both Blur Model:  number of incorrect predictions: 97  Accuracy Rate 90.3%\n"
     ]
    }
   ],
   "source": [
    "#def P6():\n",
    "    \n",
    "### STUDENT START ###\n",
    "def blur_digit(image_data):\n",
    "    new_image = []\n",
    "    pixel_neighbors = []\n",
    "\n",
    "    #loop through all pixels in the image\n",
    "    for pixel_x in range(0,28):\n",
    "        for pixel_y in range(0,28):\n",
    "            #error handle edges\n",
    "            if pixel_y >=27:\n",
    "                pixel_right = pixel_y\n",
    "            else:\n",
    "                pixel_right = pixel_y+1\n",
    "            if pixel_x >=27:\n",
    "                pixel_skip = pixel_x\n",
    "            else: \n",
    "                pixel_skip = pixel_x +1\n",
    "            #row above\n",
    "            neighbor_top= image_data[pixel_skip,(pixel_y-1,pixel_y,pixel_right)] \n",
    "            pixel_neighbors.append(neighbor_top)\n",
    "            #current row\n",
    "            neighbor_same = image_data[pixel_x,(pixel_y-1,pixel_y,pixel_right)]\n",
    "            pixel_neighbors.append(neighbor_same)\n",
    "            #row below\n",
    "            neighbor_bottom = image_data[pixel_x-1,(pixel_y-1,pixel_y,pixel_right)]\n",
    "            pixel_neighbors.append(neighbor_bottom)\n",
    "\n",
    "            #weight old pixel and calc new pixel\n",
    "            new_pixel = np.mean(pixel_neighbors)\n",
    "            new_image.append(new_pixel)\n",
    "            pixel_neighbors = []\n",
    "    return (new_image)\n",
    "\n",
    "#train_data, train_labels = X[:60000], Y[:60000]\n",
    "\n",
    "#apply blur to mini_train\n",
    "blur_mini_train = []\n",
    "for digit_pic_cnt in range(0, len(mini_train_data)):\n",
    "    image_pre_blur = np.reshape(mini_train_data[digit_pic_cnt,], (28, 28))\n",
    "    post_blur = blur_digit(image_pre_blur)\n",
    "    blur_mini_train.append(post_blur)\n",
    "\n",
    "#apply blur to test\n",
    "blur_test_data = []\n",
    "for digit_pic_cnt in range(0, len(test_data)):\n",
    "    image_pre_blur = np.reshape(test_data[digit_pic_cnt,], (28, 28))\n",
    "    post_blur = blur_digit(image_pre_blur)\n",
    "    blur_test_data.append(post_blur)\n",
    "\n",
    "#apply blur to dev\n",
    "blur_dev_data = []\n",
    "for digit_pic_cnt in range(0, len(dev_data)):\n",
    "    image_pre_blur = np.reshape(dev_data[digit_pic_cnt,], (28, 28))\n",
    "    post_blur = blur_digit(image_pre_blur)\n",
    "    blur_dev_data.append(post_blur)\n",
    "\n",
    "#builds model BASE\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(mini_train_data, mini_train_labels)\n",
    "#makes predictions on the dev dataset with the model we just built\n",
    "test_predicted_labels = model.predict(dev_data)\n",
    "#accuracy Calcs\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "print \"Vanilla Model (no blur):\",\n",
    "print ' number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((test_predicted_labels == dev_labels))/float(len(dev_labels))*100\n",
    "print ' Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "#builds model MINI TRAIN BLUR\n",
    "model_train_blur = KNeighborsClassifier(n_neighbors=1)\n",
    "model_train_blur.fit(blur_mini_train, mini_train_labels)\n",
    "#makes predictions on the dev dataset with the model we just built\n",
    "test_predicted_labels = model_train_blur.predict(dev_data)\n",
    "#accuracy Calcs\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "print \"Train Blur Model:\",\n",
    "print ' number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((test_predicted_labels == dev_labels))/float(len(dev_labels))*100\n",
    "print ' Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "#builds model DEV BLUR\n",
    "model_dev_blur = KNeighborsClassifier(n_neighbors=1)\n",
    "model_dev_blur.fit(mini_train_data, mini_train_labels)\n",
    "#makes predictions on the dev dataset with the model we just built\n",
    "test_predicted_labels = model_dev_blur .predict(blur_dev_data)\n",
    "#accuracy Calcs\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "print \"Dev Blur Model:\",\n",
    "print ' number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((test_predicted_labels == dev_labels))/float(len(dev_labels))*100\n",
    "print ' Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "#builds model BOTH BLUR\n",
    "model_both_blur = KNeighborsClassifier(n_neighbors=1)\n",
    "model_both_blur.fit(blur_mini_train, mini_train_labels)\n",
    "#makes predictions on the dev dataset with the model we just built\n",
    "test_predicted_labels = model_both_blur.predict(blur_dev_data)\n",
    "#accuracy Calcs\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "print \"Both Blur Model:\",\n",
    "print ' number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((test_predicted_labels == dev_labels))/float(len(dev_labels))*100\n",
    "print ' Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "### STUDENT END ###\n",
    "\n",
    "#P6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1088e550>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAJCCAYAAADOe7N5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106af400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAJCCAYAAADOe7N5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUIkiAIBKFAEAVKIIAKCq/wfTWqY3+2IQ/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a2f5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#def P6():\n",
    "    \n",
    "### STUDENT START ###\n",
    "fig, axes = plt.subplots(1,1,figsize=(10,10))\n",
    "image_i_data = np.reshape(mini_train_data[1,], (28, 28))\n",
    "#Show the image of the one number and converts the image to black and white\n",
    "plt.imshow(image_i_data,cmap='gray_r')\n",
    "\n",
    "def blur_digit(image_i_data)\n",
    "new_image = []\n",
    "\n",
    "#loop through all pixels in the image\n",
    "for pixel_x in range(0,28):\n",
    "    for pixel_y in range(0,28):\n",
    "        #error handle edges\n",
    "        if pixel_y >=27:\n",
    "            pixel_right = pixel_y\n",
    "        else:\n",
    "            pixel_right = pixel_y+1\n",
    "        if pixel_x >=27:\n",
    "            pixel_skip = pixel_x\n",
    "        else: \n",
    "            pixel_skip = pixel_x +1\n",
    "        #row above\n",
    "        neighbor_top= image_i_data[pixel_skip,(pixel_y-1,pixel_y,pixel_right)] \n",
    "        pixel_neighbors.append(neighbor_top)\n",
    "        #current row\n",
    "        neighbor_same = image_i_data[pixel_x,(pixel_y-1,pixel_y,pixel_right)]\n",
    "        pixel_neighbors.append(neighbor_same)\n",
    "        #row below\n",
    "        neighbor_bottom = image_i_data[pixel_x-1,(pixel_y-1,pixel_y,pixel_right)]\n",
    "        pixel_neighbors.append(neighbor_bottom)\n",
    "\n",
    "        #weight old pixel and calc new pixel\n",
    "        new_pixel = np.mean(pixel_neighbors)\n",
    "        new_image.append(new_pixel)\n",
    "        pixel_neighbors = []\n",
    "return (new_image)\n",
    "        \n",
    "### STUDENT START ###\n",
    "fig, axes = plt.subplots(1,1,figsize=(10,10))\n",
    "image_i_data2 = np.reshape(new_image, (28, 28))\n",
    "#Show the image of the one number and converts the image to black and white\n",
    "plt.imshow(image_i_data2,cmap='gray_r')\n",
    "\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Fit a Naive Bayes classifier and report accuracy on the dev data. Remember that Naive Bayes estimates P(feature|label). While sklearn can handle real-valued features, let's start by mapping the pixel values to either 0 or 1. You can do this as a preprocessing step, or with the binarize argument. With binary-valued features, you can use BernoulliNB. Next try mapping the pixel values to 0, 1, or 2, representing white, grey, or black. This mapping requires MultinomialNB. Does the multi-class version improve the results? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB Model -  number of incorrect predictions: 155 ; Accuracy Rate 84.5%\n",
      "Multinomial NB Model -  number of incorrect predictions: 173 ; Accuracy Rate 82.7%\n"
     ]
    }
   ],
   "source": [
    "#def P7():\n",
    "\n",
    "### STUDENT START ###\n",
    "#map pixel color to 0 or 1\n",
    "gnb_model = BernoulliNB(binarize=0.5) #binarizer function is cutting off here!!\n",
    "gnb_pred = gnb_model.fit(train_data, train_labels).predict(dev_data)\n",
    "wrong_prediction = (gnb_pred != dev_labels)\n",
    "print \"Bernoulli NB Model - \",\n",
    "print 'number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((gnb_pred == dev_labels))/float(len(dev_labels))*100\n",
    "print '; Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "#map pixel color to 0,1,2 (black, grey, white)\n",
    "train_bins = []\n",
    "for p in range(0,len(train_data)):\n",
    "    temp = train_data[p] \n",
    "    temp2 = np.where(temp>0.66,2,(np.where(temp>.33, 1,0))) #\n",
    "    train_bins.append(temp2) \n",
    "#print np.shape(mini_train_bins)\n",
    "\n",
    "#build multiclass model\n",
    "clf_model = MultinomialNB()\n",
    "clf_pred = clf_model.fit(train_bins, train_labels).predict(dev_data)\n",
    "wrong_prediction = (clf_pred != dev_labels)\n",
    "print \"Multinomial NB Model - \",\n",
    "print 'number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((clf_pred == dev_labels))/float(len(dev_labels))*100\n",
    "print '; Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "    \n",
    "### STUDENT END ###\n",
    "\n",
    "#P7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: The mutinomial class model did not perform any better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) Use GridSearchCV to perform a search over values of alpha (the Laplace smoothing parameter) in a Bernoulli NB model. What is the best value for alpha? What is the accuracy when alpha=0? Is this what you'd expect?\n",
    "\n",
    "- Note that GridSearchCV partitions the training data so the results will be a bit different than if you used the dev data for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=BernoulliNB(alpha=1.0, binarize=0.5, class_prior=None, fit_prior=True),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "0.821\n",
      "0.01\n",
      "scores [0.803, 0.818, 0.82, 0.821, 0.815, 0.8, 0.795, 0.784, 0.72]\n",
      "alphas [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n"
     ]
    }
   ],
   "source": [
    "def P8(alphas):\n",
    "\n",
    "### STUDENT START ###\n",
    "    #build bNB model\n",
    "    gnb_model = BernoulliNB(binarize=0.5) #binarizer function is cutting off here!!\n",
    "\n",
    "    grid = GridSearchCV(estimator=gnb_model, param_grid=alphas)\n",
    "    grid.fit(mini_train_data, mini_train_labels)\n",
    "    print(grid)\n",
    "    # summarize the results of the grid search\n",
    "    print(grid.best_score_)\n",
    "    print(grid.best_estimator_.alpha)\n",
    "\n",
    "    scores = [x[1] for x in grid.grid_scores_]\n",
    "    print 'scores',\n",
    "    print scores\n",
    "    \n",
    "    print 'alphas',\n",
    "    print [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "alphas = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "nb = P8(alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:Is this a trick question??? I'm getting an error message that says 'alpha too small will result in numeric errors, setting alpha = 1.0e-10 (the _ALPHA_MIN). Looking at the code in the package --> The sklearn library (https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/naive_bayes.py) has error handling to prevent an alpha of zero:\n",
    "\n",
    "    def _check_alpha(self):\n",
    "        if self.alpha < 0:\n",
    "            raise ValueError('Smoothing parameter alpha = %.1e. '\n",
    "                             'alpha should be > 0.' % self.alpha)\n",
    "        if self.alpha < _ALPHA_MIN:\n",
    "            warnings.warn('alpha too small will result in numeric errors, '\n",
    "                          'setting alpha = %.1e' % _ALPHA_MIN)\n",
    "            return _ALPHA_MIN\n",
    "        return self.alpha\n",
    "It looks like the script is using the log function (in 'update_feature_log_prob(alpha)) and of course you can't take the log of 0. Other than that, the alpha of 0.01 works best on the mini training dataset and the alpha of 0.001 works best when the entire training set is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to function call (<ipython-input-100-130d8e175f4d>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-100-130d8e175f4d>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    '%f'.format(unique_elements), counts_elements = np.unique(np.round(gnb_model.theta_,1), return_counts=True)\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to function call\n"
     ]
    }
   ],
   "source": [
    "#key digits of interest (most incorrect)\n",
    "unique_elements, counts_elements = np.unique(np.round(gnb_model.sigma_,1), return_counts=True)\n",
    "print(\"Frequency of unique values of the incorrect predictions:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "'%f'.format(unique_elements), counts_elements = np.unique(np.round(gnb_model.theta_,1), return_counts=True)\n",
    "print(\"Frequency of unique values of the incorrect predictions:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(9) Try training a model using GuassianNB, which is intended for real-valued features, and evaluate on the dev data. You'll notice that it doesn't work so well. Try to diagnose the problem. You should be able to find a simple fix that returns the accuracy to around the same rate as BernoulliNB. Explain your solution.\n",
    "\n",
    "Hint: examine the parameters estimated by the fit() method, theta\\_ and sigma\\_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guassian NB Model\n",
      "number of incorrect predictions: 379 ; Accuracy Rate 62.1%\n",
      "[[  1.98697608e-10   1.98697608e-10   1.98697608e-10 ...,   1.98697608e-10\n",
      "    1.98697608e-10   1.98697608e-10]\n",
      " [  1.98697608e-10   1.98697608e-10   1.98697608e-10 ...,   1.98697608e-10\n",
      "    1.98697608e-10   1.98697608e-10]\n",
      " [  1.98697608e-10   1.98697608e-10   1.98697608e-10 ...,   1.98697608e-10\n",
      "    1.98697608e-10   1.98697608e-10]\n",
      " ..., \n",
      " [  1.98697608e-10   1.98697608e-10   1.98697608e-10 ...,   1.98697608e-10\n",
      "    1.98697608e-10   1.98697608e-10]\n",
      " [  1.98697608e-10   1.98697608e-10   1.98697608e-10 ...,   1.98697608e-10\n",
      "    1.98697608e-10   1.98697608e-10]\n",
      " [  1.98697608e-10   1.98697608e-10   1.98697608e-10 ...,   1.98697608e-10\n",
      "    1.98697608e-10   1.98697608e-10]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[ 0.092  0.106  0.106  0.112  0.091  0.088  0.101  0.101  0.092  0.111]\n",
      "Guassian NB Equal Priors Model\n",
      "number of incorrect predictions: 379 ; Accuracy Rate 62.1%\n",
      "[[  1.98697608e-10   1.98697608e-10   1.98697608e-10 ...,   1.98697608e-10\n",
      "    1.98697608e-10   1.98697608e-10]\n",
      " [  1.98697608e-10   1.98697608e-10   1.98697608e-10 ...,   1.98697608e-10\n",
      "    1.98697608e-10   1.98697608e-10]\n",
      " [  1.98697608e-10   1.98697608e-10   1.98697608e-10 ...,   1.98697608e-10\n",
      "    1.98697608e-10   1.98697608e-10]\n",
      " ..., \n",
      " [  1.98697608e-10   1.98697608e-10   1.98697608e-10 ...,   1.98697608e-10\n",
      "    1.98697608e-10   1.98697608e-10]\n",
      " [  1.98697608e-10   1.98697608e-10   1.98697608e-10 ...,   1.98697608e-10\n",
      "    1.98697608e-10   1.98697608e-10]\n",
      " [  1.98697608e-10   1.98697608e-10   1.98697608e-10 ...,   1.98697608e-10\n",
      "    1.98697608e-10   1.98697608e-10]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "Guassian NB ceiling Transformation Model\n",
      "number of incorrect predictions: 397 ; Accuracy Rate 60.3%\n",
      "Guassian NB log10 Transformation Model\n",
      "number of incorrect predictions: 398 ; Accuracy Rate 60.2%\n",
      "[[  8.38423228e-09   8.38423228e-09   8.38423228e-09 ...,   8.38423228e-09\n",
      "    8.38423228e-09   8.38423228e-09]\n",
      " [  8.38423228e-09   8.38423228e-09   8.38423228e-09 ...,   8.38423228e-09\n",
      "    8.38423228e-09   8.38423228e-09]\n",
      " [  8.38423228e-09   8.38423228e-09   8.38423228e-09 ...,   8.38423228e-09\n",
      "    8.38423228e-09   8.38423228e-09]\n",
      " ..., \n",
      " [  8.38423228e-09   8.38423228e-09   8.38423228e-09 ...,   8.38423228e-09\n",
      "    8.38423228e-09   8.38423228e-09]\n",
      " [  8.38423228e-09   8.38423228e-09   8.38423228e-09 ...,   8.38423228e-09\n",
      "    8.38423228e-09   8.38423228e-09]\n",
      " [  8.38423228e-09   8.38423228e-09   8.38423228e-09 ...,   8.38423228e-09\n",
      "    8.38423228e-09   8.38423228e-09]]\n",
      "[[ 6.  6.  6. ...,  6.  6.  6.]\n",
      " [ 6.  6.  6. ...,  6.  6.  6.]\n",
      " [ 6.  6.  6. ...,  6.  6.  6.]\n",
      " ..., \n",
      " [ 6.  6.  6. ...,  6.  6.  6.]\n",
      " [ 6.  6.  6. ...,  6.  6.  6.]\n",
      " [ 6.  6.  6. ...,  6.  6.  6.]]\n",
      "Guassian NB square Transformation Model\n",
      "number of incorrect predictions: 377 ; Accuracy Rate 62.3%\n",
      "[[  2.02888619e-10   2.02888619e-10   2.02888619e-10 ...,   2.02888619e-10\n",
      "    2.02888619e-10   2.02888619e-10]\n",
      " [  2.02888619e-10   2.02888619e-10   2.02888619e-10 ...,   2.02888619e-10\n",
      "    2.02888619e-10   2.02888619e-10]\n",
      " [  2.02888619e-10   2.02888619e-10   2.02888619e-10 ...,   2.02888619e-10\n",
      "    2.02888619e-10   2.02888619e-10]\n",
      " ..., \n",
      " [  2.02888619e-10   2.02888619e-10   2.02888619e-10 ...,   2.02888619e-10\n",
      "    2.02888619e-10   2.02888619e-10]\n",
      " [  2.02888619e-10   2.02888619e-10   2.02888619e-10 ...,   2.02888619e-10\n",
      "    2.02888619e-10   2.02888619e-10]\n",
      " [  2.02888619e-10   2.02888619e-10   2.02888619e-10 ...,   2.02888619e-10\n",
      "    2.02888619e-10   2.02888619e-10]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "Guassian NB square Transformation Model\n",
      "number of incorrect predictions: 362 ; Accuracy Rate 63.8%\n",
      "[[  2.02595984e-10   2.02595984e-10   2.02595984e-10 ...,   2.02595984e-10\n",
      "    2.02595984e-10   2.02595984e-10]\n",
      " [  2.02595984e-10   2.02595984e-10   2.02595984e-10 ...,   2.02595984e-10\n",
      "    2.02595984e-10   2.02595984e-10]\n",
      " [  2.02595984e-10   2.02595984e-10   2.02595984e-10 ...,   2.02595984e-10\n",
      "    2.02595984e-10   2.02595984e-10]\n",
      " ..., \n",
      " [  2.02595984e-10   2.02595984e-10   2.02595984e-10 ...,   2.02595984e-10\n",
      "    2.02595984e-10   2.02595984e-10]\n",
      " [  2.02595984e-10   2.02595984e-10   2.02595984e-10 ...,   2.02595984e-10\n",
      "    2.02595984e-10   2.02595984e-10]\n",
      " [  2.02595984e-10   2.02595984e-10   2.02595984e-10 ...,   2.02595984e-10\n",
      "    2.02595984e-10   2.02595984e-10]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "Guassian NB square Transformation Model\n",
      "number of incorrect predictions: 460 ; Accuracy Rate 54.0%\n",
      "Guassian NB noise2 Transformation Model\n",
      "number of incorrect predictions: 258 ; Accuracy Rate 74.2%\n",
      "[[ 0.84841451  0.99036677  0.92674077 ...,  0.92369513  1.12038639\n",
      "   1.11253769]\n",
      " [ 0.90006789  1.27216152  1.13124359 ...,  0.8178257   1.19766786\n",
      "   0.82554172]\n",
      " [ 1.1305018   1.1346366   1.18147776 ...,  1.36510668  0.84068248\n",
      "   1.00692471]\n",
      " ..., \n",
      " [ 1.03330828  0.96353717  1.04022949 ...,  0.80867855  1.05896659\n",
      "   0.95991617]\n",
      " [ 1.08395031  0.98532072  1.02204977 ...,  0.84306005  1.22408274\n",
      "   1.21865423]\n",
      " [ 0.81504896  1.14379276  1.15624712 ...,  0.95669599  1.2416184\n",
      "   1.01979162]]\n",
      "[[-0.01748554  0.03094695 -0.08280022 ...,  0.03586823  0.09599336\n",
      "   0.14133493]\n",
      " [-0.01369503 -0.1016162   0.10176887 ..., -0.10674833  0.01182377\n",
      "  -0.0668294 ]\n",
      " [-0.10462476 -0.01496905 -0.12409921 ..., -0.02499504 -0.03098184\n",
      "  -0.08322728]\n",
      " ..., \n",
      " [-0.03450892  0.03259465 -0.0932061  ...,  0.09929736 -0.02796682\n",
      "   0.06301723]\n",
      " [ 0.02313025  0.1447702  -0.14617071 ..., -0.05285802  0.01968807\n",
      "   0.10183643]\n",
      " [-0.02471712  0.17411716  0.08609887 ..., -0.12481273  0.06921515\n",
      "  -0.04484234]]\n"
     ]
    }
   ],
   "source": [
    "#def P9():\n",
    "\n",
    "### STUDENT END ###\n",
    "#build vanilla gaussian model\n",
    "gnb_model = GaussianNB() \n",
    "gnb_pred = gnb_model.fit(mini_train_data, mini_train_labels).predict(dev_data)\n",
    "wrong_prediction = (gnb_pred != dev_labels)\n",
    "print \"Guassian NB Model\"\n",
    "print 'number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((gnb_pred == dev_labels))/float(len(dev_labels))*100\n",
    "print '; Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "\n",
    "print(gnb_model.sigma_)\n",
    "print(gnb_model.theta_)\n",
    "\n",
    "#testing with equal priors\n",
    "print(gnb_model.class_prior_)\n",
    "gnb_model = GaussianNB(priors=[0.1, 0.1, 0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1]) \n",
    "gnb_pred = gnb_model.fit(mini_train_data, mini_train_labels).predict(dev_data)\n",
    "wrong_prediction = (gnb_pred != dev_labels)\n",
    "print \"Guassian NB Equal Priors Model\"\n",
    "print 'number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((gnb_pred == dev_labels))/float(len(dev_labels))*100\n",
    "print '; Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "print(gnb_model.sigma_)\n",
    "print(gnb_model.theta_)\n",
    "\n",
    "#testing taking the ceiling of data\n",
    "#applying transformation to enhance the model\n",
    "trans_mini_train = np.ceil(mini_train_data)\n",
    "trans_dev_data = np.ceil(dev_data)\n",
    "#accuracy of new model\n",
    "gnb_pred = gnb_model.fit(trans_mini_train, mini_train_labels).predict(trans_dev_data)\n",
    "wrong_prediction = (gnb_pred != dev_labels)\n",
    "print \"Guassian NB ceiling Transformation Model\"\n",
    "print 'number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((gnb_pred == dev_labels))/float(len(dev_labels))*100\n",
    "print '; Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "#testing taking the log of data\n",
    "#applying transformation to enhance the model\n",
    "trans_mini_train = abs(np.log10(mini_train_data+.000001))\n",
    "trans_dev_data = abs(np.log10(dev_data+.000001))\n",
    "#accuracy of new model\n",
    "gnb_pred = gnb_model.fit(trans_mini_train, mini_train_labels).predict(trans_dev_data)\n",
    "wrong_prediction = (gnb_pred != dev_labels)\n",
    "print \"Guassian NB log10 Transformation Model\"\n",
    "print 'number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((gnb_pred == dev_labels))/float(len(dev_labels))*100\n",
    "print '; Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "print(gnb_model.sigma_)\n",
    "print(gnb_model.theta_)\n",
    "\n",
    "#testing taking the square of data\n",
    "#applying transformation to enhance the model\n",
    "trans_mini_train = np.square(mini_train_data)\n",
    "trans_dev_data = np.square(dev_data)\n",
    "#accuracy of new model\n",
    "gnb_pred = gnb_model.fit(trans_mini_train, mini_train_labels).predict(trans_dev_data)\n",
    "wrong_prediction = (gnb_pred != dev_labels)\n",
    "print \"Guassian NB square Transformation Model\"\n",
    "print 'number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((gnb_pred == dev_labels))/float(len(dev_labels))*100\n",
    "print '; Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "print(gnb_model.sigma_)\n",
    "print(gnb_model.theta_)\n",
    "\n",
    "#testing raising the data to the power of 5\n",
    "#applying transformation to enhance the model\n",
    "trans_mini_train = np.power(mini_train_data,5)\n",
    "trans_dev_data = np.power(dev_data,5)\n",
    "#accuracy of new model\n",
    "gnb_pred = gnb_model.fit(trans_mini_train, mini_train_labels).predict(trans_dev_data)\n",
    "wrong_prediction = (gnb_pred != dev_labels)\n",
    "print \"Guassian NB square Transformation Model\"\n",
    "print 'number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((gnb_pred == dev_labels))/float(len(dev_labels))*100\n",
    "print '; Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "print(gnb_model.sigma_)\n",
    "print(gnb_model.theta_)\n",
    "\n",
    "#testing adding random noise\n",
    "#applying transformation to enhance the model\n",
    "trans_mini_train = (np.random.normal(mini_train_data))\n",
    "trans_dev_data = np.random.normal(dev_data)\n",
    "#accuracy of new model\n",
    "gnb_pred = gnb_model.fit(trans_mini_train, mini_train_labels).predict(trans_dev_data)\n",
    "wrong_prediction = (gnb_pred != dev_labels)\n",
    "print \"Guassian NB square Transformation Model\"\n",
    "print 'number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((gnb_pred == dev_labels))/float(len(dev_labels))*100\n",
    "print '; Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "#random noise try 2\n",
    "noise = np.random.normal(mini_train_data)\n",
    "#print noise[1,]\n",
    "trans_mini_train = np.add(mini_train_data,noise)\n",
    "noise2 = np.random.normal(dev_data)\n",
    "trans_dev_data = np.add(dev_data, noise2)\n",
    "#accuracy of new model\n",
    "gnb_pred = gnb_model.fit(trans_mini_train, mini_train_labels).predict(trans_dev_data)\n",
    "wrong_prediction = (gnb_pred != dev_labels)\n",
    "print \"Guassian NB noise2 Transformation Model\"\n",
    "print 'number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((gnb_pred == dev_labels))/float(len(dev_labels))*100\n",
    "print '; Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "print(gnb_model.sigma_)\n",
    "print(gnb_model.theta_)\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#gnb = P9()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.49440864e-01   7.40647334e-01   5.60808263e-01   8.80985555e-01\n",
      "   1.46015162e+00   1.75779005e+00   4.80048508e-01  -2.02623282e+00\n",
      "   1.47518427e+00  -1.03446004e+00   5.41777724e-01   1.05713932e-03\n",
      "   1.76555277e+00   8.66982553e-01   8.40818864e-01  -1.38895159e-01\n",
      "   7.10533818e-01   1.31840019e-01   6.05678053e-01  -2.29559049e-01\n",
      "  -7.87659723e-01  -9.44241198e-01   7.59413580e-01  -5.72919989e-01\n",
      "   4.21559804e-01  -7.10309090e-01   9.01348699e-01  -9.64799749e-01\n",
      "  -6.01490305e-01   4.93072585e-01  -2.12330588e+00   1.54740068e+00\n",
      "  -9.23489202e-01  -1.37391142e+00   1.25667867e+00  -3.44371321e-01\n",
      "   6.00820601e-01   1.94972258e+00  -4.39164320e-01  -8.29863129e-01\n",
      "  -7.27213675e-01   1.11765330e+00  -5.77956892e-01  -6.41034651e-02\n",
      "  -4.90063487e-01   1.51321648e+00  -1.51370714e+00  -2.45508856e-01\n",
      "  -8.48700092e-01  -2.62775262e-01  -2.93705771e-02  -3.23699498e-01\n",
      "  -9.38957162e-01   7.97879090e-01   6.42741098e-01   3.85771146e-01\n",
      "   2.05477175e-01  -2.50795553e+00  -1.28937644e+00  -4.40623907e-01\n",
      "  -1.34443327e-01   1.67678346e+00  -1.24039916e+00   2.11647829e-02\n",
      "  -2.04093417e+00  -1.63994083e+00  -2.32693439e-02  -8.43440842e-01\n",
      "  -6.58898737e-01   3.43901379e-01   1.08142275e+00   8.31384183e-01\n",
      "   1.60622770e-02  -1.02552075e-01  -3.00903891e-01   2.25364210e+00\n",
      "  -2.50017202e+00  -1.01418648e-01   9.02779194e-01   3.43665777e-01\n",
      "   7.33150319e-01   1.55618484e+00   1.13433404e+00  -2.90239764e-01\n",
      "   1.41434285e+00   2.54502129e-01   2.31155414e-01  -2.53288345e+00\n",
      "  -1.57692148e+00  -3.61704137e-01   2.38540305e-01   2.21061737e-01\n",
      "   6.01260906e-01  -1.24290575e+00   1.73105320e+00   8.21671318e-02\n",
      "   6.74313642e-01   2.16776696e+00  -1.06934597e+00   3.08268536e-01\n",
      "  -9.33505835e-01   4.93670740e-01  -1.29534946e+00  -1.36615136e+00\n",
      "   9.26951802e-01   1.75149457e+00  -2.31313140e-02  -4.24185968e-01\n",
      "  -9.64070141e-01  -1.34631745e+00  -1.57013093e+00   1.93043712e+00\n",
      "  -3.85742870e-01   8.25422728e-01  -7.59339655e-01   8.67631714e-01\n",
      "  -1.09736358e+00  -1.97180842e+00  -1.16985584e+00  -7.99193805e-01\n",
      "   1.85211144e+00   3.85200581e-01   1.60790625e+00   6.53743288e-01\n",
      "  -1.16769379e+00   1.18747786e+00  -1.17995630e+00  -1.61017155e+00\n",
      "  -1.87009172e+00   5.74885768e-01  -1.94267166e+00  -1.76235316e-01\n",
      "  -9.00512048e-01  -1.03007391e+00  -2.15937819e+00  -7.65090648e-01\n",
      "   2.20286554e+00  -9.70956339e-01  -1.89641711e-01   1.05466831e+00\n",
      "   2.56408609e-01  -1.34995459e-01  -1.13697663e+00   7.60462578e-01\n",
      "   1.39090934e+00   5.51837313e-01  -7.87904102e-01   1.05259676e+00\n",
      "   9.11461300e-01   6.73751333e-01  -3.37793673e-01   2.34017750e+00\n",
      "   2.67923374e-03  -2.03370006e+00   6.08894933e-01  -1.03509416e+00\n",
      "   8.04594992e-01  -6.92959444e-01  -6.75023225e-01  -2.78479656e-01\n",
      "   1.72324025e+00  -1.44643949e+00  -3.88356252e-01  -8.65831898e-01\n",
      "  -1.73430564e+00  -2.28405405e+00  -5.21134834e-01  -1.94583115e+00\n",
      "  -1.48238704e+00  -8.18974575e-01   4.14609637e-01   2.02959104e-02\n",
      "   1.57784226e-01   8.23085850e-01   9.58516775e-01   6.13262275e-01\n",
      "  -1.70094763e+00  -1.17835371e+00  -7.33906619e-02   4.33026875e-01\n",
      "   1.02525451e+00   8.79315885e-01   1.63268828e+00   1.06109374e+00\n",
      "   8.92719630e-01   1.32591502e+00  -2.39395748e+00  -3.31601531e-01\n",
      "  -5.62434662e-02   4.30491479e-01   1.09609631e+00   1.28803770e+00\n",
      "   1.36540063e+00   1.26373139e+00  -1.93393588e+00   1.26818906e+00\n",
      "   2.54130475e-01   1.53842514e-02   7.44294272e-01   6.10245474e-01\n",
      "   1.63435239e-01   4.21150371e-01  -7.03785726e-01   5.65563063e-01\n",
      "   2.71584334e+00  -9.12087286e-02  -1.52673594e+00   1.95411484e+00\n",
      "  -1.20630386e-01   7.62533123e-01  -8.11333749e-01  -4.09192617e-01\n",
      "  -2.65337044e-01   1.98280051e+00   8.25507726e-01   3.47843813e-01\n",
      "  -1.29916300e+00   1.45392474e+00  -1.12470995e+00  -9.15302992e-01\n",
      "  -8.76063483e-01  -3.49422579e-01   1.00737841e-01   2.43081930e+00\n",
      "   9.40708189e-03   1.48306288e-02   2.99707219e-01   1.92972317e+00\n",
      "  -1.35877053e+00   1.08455175e+00   1.09361936e+00   8.09566829e-01\n",
      "  -8.67332868e-01   8.39425540e-01   1.92262683e+00  -3.37833227e-01\n",
      "   2.48287685e+00   5.54655439e-01  -1.34667814e+00   5.55471425e-01\n",
      "   3.38650094e-01   1.43902731e+00   9.64558652e-01   4.26901343e-01\n",
      "  -6.02889347e-01  -1.13325845e+00   6.69118821e-01  -7.91435954e-01\n",
      "  -1.49335671e-02   2.01265218e+00   5.15205843e-02  -6.24469529e-01\n",
      "   2.80502390e-01   2.49202986e-02   3.16172437e-01   1.17800171e+00\n",
      "  -1.11433782e+00  -1.30034074e+00   1.99018103e+00   1.93517194e-01\n",
      "   2.88326888e-01   8.27380657e-01   1.99601716e+00   1.99536352e+00\n",
      "   3.99043374e-02   1.75531002e-02   1.62175478e+00  -9.99170872e-01\n",
      "   1.32735416e+00   9.35276501e-01   8.10325498e-01   4.72373414e-01\n",
      "  -1.79498609e+00   3.80785425e-01   1.62661210e+00   6.55212992e-01\n",
      "  -6.82533966e-01  -3.89761189e-01  -1.06283302e+00   8.45245022e-01\n",
      "  -4.00405958e-01   1.02228699e-01   3.37153783e-01   5.35031374e-01\n",
      "   1.45034284e+00   1.30646781e+00   4.99849719e-01   6.23346617e-02\n",
      "   1.16470482e+00   1.16470161e+00   1.25542552e+00   1.44546130e+00\n",
      "  -3.58820487e-01  -2.67888175e+00   5.45766268e-01  -6.53796054e-01\n",
      "   1.93103863e-01   1.70341806e+00   7.05871246e-01   6.82478117e-01\n",
      "   9.04797161e-01   2.12470130e-03  -1.72416944e+00  -1.15344507e+00\n",
      "  -1.66574395e+00  -8.62208033e-01   1.62785984e+00  -5.16642473e-01\n",
      "   1.18649340e+00  -1.24667541e+00  -9.94505212e-01  -9.10583794e-01\n",
      "   5.30437510e-01   8.45018636e-01   3.28762923e-01  -5.11023827e-01\n",
      "   1.74486146e+00  -2.13196485e-01  -1.68399332e-01  -1.34321997e+00\n",
      "   1.15769729e+00   2.29472353e-01  -1.24553757e+00   2.30872938e-01\n",
      "   4.49949234e-01  -1.09283158e+00   3.32513857e-01   3.44026451e+00\n",
      "   6.20787023e-01  -4.89238180e-01  -4.13911910e-01  -1.58554995e-01\n",
      "  -1.22646214e+00  -6.53805258e-02   1.97060228e+00  -5.12576040e-01\n",
      "  -6.51218922e-01  -1.13380780e-01  -1.03725446e+00   2.34773135e-01\n",
      "   1.26940139e-01  -7.59522372e-01   8.42455034e-01  -6.28569438e-02\n",
      "  -1.70415783e-01   1.90688155e+00   9.91804503e-01   1.90379332e+00\n",
      "  -8.91612858e-01   1.35088917e+00   6.36207206e-01   3.16683422e-01\n",
      "   7.83979561e-03   2.91080242e-02   1.89820177e+00   1.94617965e+00\n",
      "   1.71711760e-01  -8.13100247e-01   1.04603700e+00  -7.72764339e-01\n",
      "  -4.64577102e-01  -1.84546601e+00   8.87894325e-01  -2.10415276e-01\n",
      "  -2.96973128e-01  -7.02289499e-01   1.28103977e-01  -1.28463286e+00\n",
      "  -5.90466909e-01  -6.81296234e-01   1.70567776e+00  -2.21156047e-01\n",
      "   5.72723875e-01   1.19459732e+00  -5.71652829e-02   7.67453554e-01\n",
      "  -6.48306836e-01  -3.37032908e-01   1.94399328e+00   1.37721540e+00\n",
      "   2.13559182e-01   4.16514130e-01   1.63756807e+00   1.25516255e+00\n",
      "  -7.91045574e-01   5.83860203e-01  -1.37304985e+00   2.05645538e+00\n",
      "   6.89244073e-01   4.30014588e-01  -5.73945245e-01  -4.08574577e-02\n",
      "  -1.16834950e+00   1.32328965e+00  -3.27168995e-01   1.38621305e+00\n",
      "  -6.63959853e-01   5.40466213e-01   1.10360008e+00   5.20208615e-01\n",
      "   1.22851859e+00   1.90547738e-01   1.83321832e+00   1.27383226e+00\n",
      "  -1.39630603e-01   1.29590245e+00   8.81549844e-01   4.04971544e-01\n",
      "  -4.81952071e-01   3.10734710e+00  -3.99354858e-01   1.22286020e+00\n",
      "  -1.91613207e-01  -1.00188398e+00   1.05843267e+00   1.57839018e+00\n",
      "  -1.41865298e+00  -2.20209653e-01   2.18247688e-01  -1.05085499e-01\n",
      "  -8.30391238e-02   6.50412058e-01  -2.06539651e+00   1.02276123e+00\n",
      "   5.67945208e-02  -1.69762091e+00   3.69590808e-01   1.29926656e-01\n",
      "   9.27576643e-01   3.19395632e-01   4.86457936e-01   7.52235142e-01\n",
      "  -3.30522431e-02   1.46121770e+00   1.99229527e+00   1.68175447e+00\n",
      "   1.07093433e+00   1.06363868e+00   1.62113788e+00   4.42182281e-01\n",
      "   3.28867803e-01   1.49184662e+00   4.15589468e-01  -2.00953196e+00\n",
      "   1.45263514e+00  -2.32491600e-01  -1.35151562e+00  -1.71840360e+00\n",
      "   1.45773788e+00   2.02533607e+00   3.84591548e-01   4.80871723e-01\n",
      "  -1.51244094e+00   2.91634470e+00   4.13814744e-01  -8.32608030e-01\n",
      "   1.67781283e+00   1.53826821e+00   1.78047666e+00   1.24355496e+00\n",
      "   2.87868526e-01   1.98303508e+00  -5.41894939e-01  -1.53506531e-01\n",
      "   5.93715983e-01  -7.26465236e-01   1.16000218e+00   1.44182501e+00\n",
      "  -9.68963575e-01   7.73544495e-01   1.07614581e+00   5.79146538e-01\n",
      "  -9.40857209e-01   4.63501161e-01   5.73191591e-01   3.18846807e-01\n",
      "  -5.12234118e-02   1.20285474e+00   4.10173122e-01  -9.44056854e-01\n",
      "  -1.16705390e+00  -2.67882693e-01   7.89151807e-01   8.77066184e-01\n",
      "  -6.29988594e-01   1.14402266e+00   1.47324417e+00  -1.85511473e-01\n",
      "   9.84842965e-01   6.06098434e-01  -8.05721346e-01   1.34700039e+00\n",
      "   1.76169088e+00   9.67087948e-01   9.05607339e-01  -1.75360818e+00\n",
      "  -4.83271476e-01  -3.49459568e-01  -2.79342046e-01   6.43474515e-01\n",
      "   1.19830945e-01  -5.07949067e-02  -7.98537374e-01   7.96048035e-03\n",
      "   1.95361246e-01   1.18009303e+00  -1.59249423e+00  -3.06909861e-01\n",
      "   1.36875767e+00  -9.36291023e-01  -1.20338896e+00   1.52098176e+00\n",
      "   8.64961743e-02   1.85973508e+00   5.77062452e-01  -1.53257877e+00\n",
      "   1.36842350e+00   6.73255227e-01  -9.52626923e-01  -1.43294641e-01\n",
      "  -6.81781592e-01   7.36344686e-01   1.17801727e+00  -8.11706076e-01\n",
      "   7.32465688e-01   6.23098151e-01  -4.05545977e-01   1.80769227e-01\n",
      "  -4.62106835e-01   3.81160886e-01  -1.79143786e+00  -1.77813133e-01\n",
      "  -7.14548518e-01  -4.39973885e-01  -5.50289066e-01  -7.96852389e-01\n",
      "   1.24986593e+00  -2.84549215e+00   1.11100037e+00   1.89666650e+00\n",
      "   6.20883379e-01   1.54796630e+00   2.13763236e-01  -8.42202652e-01\n",
      "  -1.12297664e+00   6.48170916e-01   2.27684013e-01   6.72694828e-01\n",
      "   1.46697665e+00   2.95797440e+00   3.57955040e-01   6.67065692e-01\n",
      "   3.22779166e-01   1.13069838e+00  -1.76483012e+00  -5.51451227e-01\n",
      "   1.16018139e+00   3.12577194e-01  -8.79538746e-01  -1.18445928e+00\n",
      "  -1.03584100e-01   8.72295408e-01   3.95554467e-01   1.35168762e+00\n",
      "  -5.83228478e-02   2.46221743e-01   6.29243215e-01   1.36402876e+00\n",
      "  -6.07160561e-01  -1.98518893e+00  -8.81841489e-01  -7.76874796e-01\n",
      "   3.17008306e-01  -4.20523074e-01  -3.17638214e-01   1.34509717e+00\n",
      "   6.27657767e-03   2.89156440e+00  -3.29896814e-01  -2.21082693e-01\n",
      "  -2.10998784e+00  -1.94930432e+00  -1.38438208e+00  -7.72361230e-01\n",
      "  -1.53221860e+00  -1.97046575e+00   1.10510798e-01  -2.59375056e-02\n",
      "  -1.34174598e+00  -4.30518938e-01  -6.42781232e-01  -7.24255948e-01\n",
      "  -7.06135806e-01   2.50165426e-01   2.78991529e-01   2.22880899e-01\n",
      "   7.42167809e-01  -9.44547855e-01   4.67438214e-01   8.60772531e-02\n",
      "   8.72965796e-01   3.09818412e-01   1.55683288e+00  -4.17275750e-01\n",
      "  -5.00733334e-02   2.73033856e+00  -6.15021055e-01   2.39706824e+00\n",
      "  -5.28702047e-01   8.95647064e-01   4.72976739e-01   2.56749285e-01\n",
      "   2.08944362e-01   2.56130051e-01   1.72756000e+00   9.08947104e-02\n",
      "  -1.06685862e-01   5.96306961e-01   1.26806172e+00  -2.41795157e+00\n",
      "   6.09154797e-01  -2.39827838e-01   6.55177366e-01   1.16656542e+00\n",
      "  -9.01404996e-01  -2.76400579e-01  -1.25141377e-01   2.68986699e-01\n",
      "  -1.38289665e+00   6.50281706e-01   1.25515005e+00   1.30207201e+00\n",
      "   1.99854231e+00  -1.25551923e+00  -6.32639596e-01   9.74480032e-01\n",
      "   8.98403152e-01   1.10895724e+00  -2.72814738e-01   1.72051048e+00\n",
      "  -1.35674443e+00  -1.35988391e-02  -2.20269506e-01   2.61585136e-01\n",
      "   2.12797337e+00  -4.70763247e-01  -3.32952972e-01  -1.07236334e+00\n",
      "   4.52048213e-01  -1.22653091e-01  -1.59636441e+00  -2.70909835e+00\n",
      "   3.02218722e-01   1.39383124e-01  -8.13632416e-01   2.38599453e-01\n",
      "   1.32007341e+00   4.42825582e-01   1.27855339e+00   1.21576761e+00\n",
      "   7.05104908e-01  -1.05783512e+00  -4.94375885e-01  -1.62370763e-01\n",
      "  -1.13275020e-01   7.57242757e-01   9.66856170e-02  -4.09467685e-01\n",
      "  -1.19857878e-01   4.31170178e-01   2.74352903e+00  -1.46874048e+00\n",
      "  -9.14303385e-02   9.37926632e-01   2.62040860e-01   8.94153449e-01\n",
      "  -8.03760672e-01   9.69669915e-01  -1.40200451e+00  -4.32805778e-02\n",
      "   1.07653521e+00   3.44242422e-01   4.11653987e-01   8.68997250e-01\n",
      "   3.07859692e+00   2.14980177e+00  -1.00559829e+00  -2.47505355e-01\n",
      "  -8.78934053e-02   1.93359710e+00  -4.64046124e-01   2.52757381e-01\n",
      "   3.39116542e-01  -3.51864871e-01  -3.95444883e-01   4.43394907e-01\n",
      "  -1.03139964e-01   1.27874226e+00  -1.10045785e-01   5.95200098e-01\n",
      "  -7.41890853e-01   1.26003060e+00   1.92963186e+00  -5.36192133e-01\n",
      "   4.56780677e-01   5.89111707e-01   3.11827209e-01   9.44146025e-01\n",
      "  -7.93686851e-01   1.03404961e+00  -3.30264421e-03   2.91079040e-01\n",
      "   8.75658519e-01   7.78747262e-01  -3.57392444e-01   3.37599376e-01\n",
      "   1.37675980e+00  -1.33667748e+00   1.10055610e+00   2.09900954e-01\n",
      "  -1.16943533e+00  -1.93960618e+00  -8.26435365e-01  -4.06841796e-01\n",
      "   4.23498459e-01   5.49261537e-01  -1.37254749e+00   5.17630727e-01\n",
      "  -1.40151947e+00  -1.17208502e+00  -3.22718469e-01   3.74642339e-01\n",
      "  -8.94236779e-01  -3.62077721e-01   1.00360657e+00   1.16548625e+00\n",
      "  -1.33296168e-01   1.31032015e-01  -1.38422860e+00  -3.93275035e-01\n",
      "  -1.30371928e+00   3.45261818e-01   1.67606358e+00   5.42151327e-01\n",
      "   1.91479066e+00  -1.68607401e+00  -4.15628436e-01   1.51461334e-01\n",
      "  -3.99300561e-01  -4.55433272e-01  -1.36448070e+00   1.00451650e+00\n",
      "   2.20926733e-01   1.18327433e+00   8.88820356e-01  -6.08984374e-01\n",
      "  -5.65048329e-01  -5.82862186e-01   1.12318632e+00  -4.11612624e-02\n",
      "  -6.57292417e-01   2.43784150e-02  -7.63361942e-01   5.34751153e-01\n",
      "   1.08265984e+00  -3.49476981e-02   1.71581419e+00  -5.99193998e-02\n",
      "  -2.24827283e-01  -2.42212595e-01   5.51276748e-01  -3.58231043e-01\n",
      "  -1.52788957e+00   3.32725280e-01  -1.70428913e+00   5.62070928e-01\n",
      "   1.43812646e-01  -2.36784582e+00   1.80513092e+00   8.00840535e-01\n",
      "  -1.06664815e+00  -2.94945978e+00  -3.43984582e+00  -6.60694187e-01]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'axis' is an invalid keyword to ufunc 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-95fed60b5492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_train_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrans_mini_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_train_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mtrans_mini_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'axis' is an invalid keyword to ufunc 'add'"
     ]
    }
   ],
   "source": [
    "noise = np.random.normal(mini_train_data)\n",
    "print noise[1,]\n",
    "trans_mini_train = np.add(mini_train_data,noise, axis = 0)\n",
    "print trans_mini_train[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mini_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10) Because Naive Bayes is a generative model, we can use the trained model to generate digits. Train a BernoulliNB model and then generate a 10x20 grid with 20 examples of each digit. Because you're using a Bernoulli model, each pixel output will be either 0 or 1. How do the generated digits compare to the training digits?\n",
    "\n",
    "- You can use np.random.rand() to generate random numbers from a uniform distribution\n",
    "- The estimated probability of each pixel is stored in feature\\_log\\_prob\\_. You'll need to use np.exp() to convert a log probability back to a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli NB Model -  number of incorrect predictions: 155 ; Accuracy Rate 84.5%\n",
      "(10L, 784L)\n",
      "[[ 0.00016844  0.00016844  0.00016844 ...,  0.00016844  0.00016844\n",
      "   0.00016844]\n",
      " [ 0.00014857  0.00014857  0.00014857 ...,  0.00014857  0.00014857\n",
      "   0.00014857]\n",
      " [ 0.0001677   0.0001677   0.0001677  ...,  0.0001677   0.0001677\n",
      "   0.0001677 ]\n",
      " ..., \n",
      " [ 0.00016088  0.00016088  0.00016088 ...,  0.00016088  0.00016088\n",
      "   0.00016088]\n",
      " [ 0.00017044  0.00017044  0.00017044 ...,  0.00017044  0.00017044\n",
      "   0.00017044]\n",
      " [ 0.00016745  0.00016745  0.00016745 ...,  0.00016745  0.00016745\n",
      "   0.00016745]]\n"
     ]
    }
   ],
   "source": [
    "#def P10(num_examples):\n",
    "\n",
    "### STUDENT START ###\n",
    "#train Bernoulli model\n",
    "gnb_model = BernoulliNB(binarize=0.5) #binarizer function is cutting off here!!\n",
    "gnb_pred = gnb_model.fit(train_data, train_labels).predict(dev_data)\n",
    "wrong_prediction = (gnb_pred != dev_labels)\n",
    "print \"Bernoulli NB Model - \",\n",
    "print 'number of incorrect predictions:', np.sum(wrong_prediction),\n",
    "accuracy_rate = np.sum((gnb_pred == dev_labels))/float(len(dev_labels))*100\n",
    "print '; Accuracy Rate ' +  \"{0:.1f}%\".format(accuracy_rate)\n",
    "\n",
    "#for each digit, every pixel has a probability\n",
    "print np.shape(gnb_model.feature_log_prob_)\n",
    "pixel_prob = np.exp(gnb_model.feature_log_prob_)\n",
    "\n",
    "#make a new dataset of random numbers\n",
    "new_digits_data = np.random.rand(200,784)\n",
    "\n",
    "#build model using new random numbers\n",
    "for digit in range(0,10):\n",
    "    for example in range(0,3):\n",
    "        new_digit_expression = new_digits_data<pixel_prob[digit] \n",
    "\n",
    "\n",
    "#print new dataset\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P10(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200L, 784L)\n",
      "(1000L, 784L)\n"
     ]
    }
   ],
   "source": [
    "new_digits_data = np.random.rand(200,784)\n",
    "print np.shape(new_digits_data)\n",
    "print np.shape(mini_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_digit_expression = np.where(new_digits_data[1,]<pixel_prob[1],1,0)\n",
    "new_digit_expression\n",
    "\n",
    "#new_digit_expression2 = np.where(new_digit_expression ==true,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00016844,  0.00016844,  0.00016844, ...,  0.00016844,\n",
       "         0.00016844,  0.00016844],\n",
       "       [ 0.00014857,  0.00014857,  0.00014857, ...,  0.00014857,\n",
       "         0.00014857,  0.00014857],\n",
       "       [ 0.0001677 ,  0.0001677 ,  0.0001677 , ...,  0.0001677 ,\n",
       "         0.0001677 ,  0.0001677 ],\n",
       "       ..., \n",
       "       [ 0.00016088,  0.00016088,  0.00016088, ...,  0.00016088,\n",
       "         0.00016088,  0.00016088],\n",
       "       [ 0.00017044,  0.00017044,  0.00017044, ...,  0.00017044,\n",
       "         0.00017044,  0.00017044],\n",
       "       [ 0.00016745,  0.00016745,  0.00016745, ...,  0.00016745,\n",
       "         0.00016745,  0.00016745]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_prob = np.exp(gnb_model.feature_log_prob_)\n",
    "pixel_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6490043841865402,\n",
       " 0.618329872067536,\n",
       " 0.6726662340655544,\n",
       " 0.30144257554182863,\n",
       " 0.5398321319832818,\n",
       " 0.967285978956996,\n",
       " 0.9702299450159019,\n",
       " 0.30571546802285887,\n",
       " 0.5225306648540899,\n",
       " 0.8093708973733595,\n",
       " 0.20010765842980216,\n",
       " 0.5606033415756432,\n",
       " 0.3653988668667878,\n",
       " 0.4988623763537058,\n",
       " 0.14315194113430574,\n",
       " 0.6585430841354801,\n",
       " 0.1881344247055332,\n",
       " 0.17744747976960173,\n",
       " 0.6355197266340276,\n",
       " 0.18744954883371956,\n",
       " 0.029033592653587736,\n",
       " 0.881086163483599,\n",
       " 0.5181324311747862,\n",
       " 0.4590011505980761,\n",
       " 0.4708828759297745,\n",
       " 0.23890151656005698,\n",
       " 0.6365084517201901,\n",
       " 0.22221364064046323,\n",
       " 0.6306682321782511,\n",
       " 0.09806934771159859,\n",
       " 0.5851334251678629,\n",
       " 0.5728168435634564,\n",
       " 0.2925263089263016,\n",
       " 0.2704588871334186,\n",
       " 0.07732081205280406,\n",
       " 0.8623638792858359,\n",
       " 0.01385630886310818,\n",
       " 0.9002602936179959,\n",
       " 0.5953870453839831,\n",
       " 0.025350920957712186,\n",
       " 0.6407958974526312,\n",
       " 0.9771463025007954,\n",
       " 0.5531336116034611,\n",
       " 0.8188840078182527,\n",
       " 0.09966065588567774,\n",
       " 0.13634274716074446,\n",
       " 0.621476959609848,\n",
       " 0.9220475969274043,\n",
       " 0.24218230001687435,\n",
       " 0.22665264427862875,\n",
       " 0.06330940735188884,\n",
       " 0.5659531887526638,\n",
       " 0.7389962500529692,\n",
       " 0.7453717294512056,\n",
       " 0.8788582933631672,\n",
       " 0.012323534623660093,\n",
       " 0.5963801481805724,\n",
       " 0.07942550965911555,\n",
       " 0.5643688526593356,\n",
       " 0.0863195729935824,\n",
       " 0.9319032296108616,\n",
       " 0.1967548473474895,\n",
       " 0.22758183444149538,\n",
       " 0.586645093509701,\n",
       " 0.21565996217121886,\n",
       " 0.14015807010278303,\n",
       " 0.7242669501213418,\n",
       " 0.5751973068688848,\n",
       " 0.9145302711906026,\n",
       " 0.4355217974099501,\n",
       " 0.5247767084331774,\n",
       " 0.3155116696526986,\n",
       " 0.9598548312664189,\n",
       " 0.95069802940085,\n",
       " 0.48369277454743864,\n",
       " 0.2961807679772579,\n",
       " 0.49270094300299594,\n",
       " 0.098063341200053,\n",
       " 0.7800735833956188,\n",
       " 0.47971811393613895,\n",
       " 0.3791872696002031,\n",
       " 0.4457132622001647,\n",
       " 0.6433808534832536,\n",
       " 0.2133243076138185,\n",
       " 0.8936223912584608,\n",
       " 0.25265362963181126,\n",
       " 0.5143536060778809,\n",
       " 0.7676813603324758,\n",
       " 0.08606226167632947,\n",
       " 0.7285210411535568,\n",
       " 0.6513743495213873,\n",
       " 0.04155474894324318,\n",
       " 0.8755532895450416,\n",
       " 0.7260024506574332,\n",
       " 0.9196088670799893,\n",
       " 0.6250533126031713,\n",
       " 0.12020358297823708,\n",
       " 0.13300602619806445,\n",
       " 0.2803165389556077,\n",
       " 0.7556450863305514,\n",
       " 0.04957379258639072,\n",
       " 0.26035961804712393,\n",
       " 0.34689342605120854,\n",
       " 0.5460451894709338,\n",
       " 0.12769981138395714,\n",
       " 0.5312886736614202,\n",
       " 0.46269916246831877,\n",
       " 0.38575970966818796,\n",
       " 0.48320296220801784,\n",
       " 0.9266968937255139,\n",
       " 0.4903329129694809,\n",
       " 0.9904721953901547,\n",
       " 0.902727537490129,\n",
       " 0.5835617720833801,\n",
       " 0.3350796867272,\n",
       " 0.0548480278643132,\n",
       " 0.5518148664257269,\n",
       " 0.9201057805888991,\n",
       " 0.5618471399341527,\n",
       " 0.5279257590252965,\n",
       " 0.2153419447959165,\n",
       " 0.6587907310461516,\n",
       " 0.7788577902420962,\n",
       " 0.9220322228591727,\n",
       " 0.008376609628835352,\n",
       " 0.31988590582310794,\n",
       " 0.3377321796533791,\n",
       " 0.523924741297993,\n",
       " 0.7843665345633537,\n",
       " 0.6513035043025776,\n",
       " 0.3525299370266318,\n",
       " 0.17051917196221966,\n",
       " 0.5456895401148758,\n",
       " 0.48120869369395003,\n",
       " 0.9245257750739834,\n",
       " 0.0991525692768287,\n",
       " 0.6267978154356718,\n",
       " 0.2840360175873726,\n",
       " 0.35573000032181445,\n",
       " 0.45339898318031435,\n",
       " 0.7403228047327091,\n",
       " 0.5494678251354089,\n",
       " 0.3760120936710406,\n",
       " 0.7513436652172142,\n",
       " 0.4820568982308221,\n",
       " 0.27198131406064385,\n",
       " 0.20224142502718623,\n",
       " 0.8849029333398547,\n",
       " 0.4134972404610531,\n",
       " 0.4737072958993158,\n",
       " 0.1939599797682524,\n",
       " 0.9673155560106017,\n",
       " 0.3609211176266224,\n",
       " 0.796277120744005,\n",
       " 0.3113708231659663,\n",
       " 0.5570575882873057,\n",
       " 0.3842229257226396,\n",
       " 0.681527465481264,\n",
       " 0.42783414729455815,\n",
       " 0.9605457524655324,\n",
       " 0.009912556357986824,\n",
       " 0.1959382771511894,\n",
       " 0.1447358139426983,\n",
       " 0.45886588685275687,\n",
       " 0.4634512345554369,\n",
       " 0.41969172677889666,\n",
       " 0.042216592114499796,\n",
       " 0.8000767612930648,\n",
       " 0.2169075857265148,\n",
       " 0.313873118486495,\n",
       " 0.5431670914894904,\n",
       " 0.1257494846509798,\n",
       " 0.9087720412545135,\n",
       " 0.28675560535678635,\n",
       " 0.5087763574873635,\n",
       " 0.7850031035831994,\n",
       " 0.21128268639221326,\n",
       " 0.688900067027529,\n",
       " 0.9697699591184851,\n",
       " 0.525200666926692,\n",
       " 0.5894869674221231,\n",
       " 0.5491551391316342,\n",
       " 0.19564575437575948,\n",
       " 0.21837447102355578,\n",
       " 0.5714223177410913,\n",
       " 0.28275507662653687,\n",
       " 0.2722757902346996,\n",
       " 0.513198491165179,\n",
       " 0.0994194437183924,\n",
       " 0.7309593858543633,\n",
       " 0.6810799129101013,\n",
       " 0.4424016436713719,\n",
       " 0.30969016188746323,\n",
       " 0.11646165752834658,\n",
       " 0.6917282920146599,\n",
       " 0.9365766339081663,\n",
       " 0.8702611825589103,\n",
       " 0.9375213440857476,\n",
       " 0.5669893598189413,\n",
       " 0.004788416112974203,\n",
       " 0.15539430704998436,\n",
       " 0.012184611755429064,\n",
       " 0.6982998182943522,\n",
       " 0.7135101428072014,\n",
       " 0.9340153688456903,\n",
       " 0.10046627814224851,\n",
       " 0.748714431720563,\n",
       " 0.030588820962954677,\n",
       " 0.9439779269234316,\n",
       " 0.14939942153425712,\n",
       " 0.3335020171665459,\n",
       " 0.4765454541767953,\n",
       " 0.9277249660642682,\n",
       " 0.7849819769354667,\n",
       " 0.22173197939817613,\n",
       " 0.04217149627436878,\n",
       " 0.0525301339505202,\n",
       " 0.32313349563631866,\n",
       " 0.44061803625918616,\n",
       " 0.09726320639198316,\n",
       " 0.44441005756798,\n",
       " 0.7587068769247721,\n",
       " 0.5949367528604986,\n",
       " 0.039386948599768545,\n",
       " 0.2370494316392331,\n",
       " 0.6938395175873343,\n",
       " 0.7731972891576562,\n",
       " 0.6590602070326368,\n",
       " 0.8161243739858632,\n",
       " 0.07754792956243195,\n",
       " 0.3355782428346007,\n",
       " 0.052724148140879556,\n",
       " 0.28765759937229984,\n",
       " 0.23621737347806981,\n",
       " 0.4856906016358975,\n",
       " 0.6522037237343101,\n",
       " 0.1027157302811893,\n",
       " 0.3404529243684682,\n",
       " 0.4672726978985876,\n",
       " 0.9892797010653505,\n",
       " 0.3969551715648808,\n",
       " 0.2940164557578261,\n",
       " 0.05858845111121369,\n",
       " 0.16339158310353796,\n",
       " 0.9345197136083869,\n",
       " 0.13409344427049918,\n",
       " 0.4633903449738379,\n",
       " 0.2107366249948649,\n",
       " 0.7424161870687634,\n",
       " 0.32243687455694925,\n",
       " 0.6030877845587594,\n",
       " 0.24567177818861652,\n",
       " 0.712017679291019,\n",
       " 0.8683950131825712,\n",
       " 0.3451562350119619,\n",
       " 0.37409798272360917,\n",
       " 0.23842192376668037,\n",
       " 0.9753875635227156,\n",
       " 0.0759878246626361,\n",
       " 0.13316065374108177,\n",
       " 0.7461412529137043,\n",
       " 0.5103724212880932,\n",
       " 0.7046809470149025,\n",
       " 0.3122426516828617,\n",
       " 0.7140698642519631,\n",
       " 0.26499558031733206,\n",
       " 0.790821623462148,\n",
       " 0.958633076934722,\n",
       " 0.40495062350882305,\n",
       " 0.567496048444509,\n",
       " 0.8468807674715955,\n",
       " 0.14381263581046067,\n",
       " 0.34679815374575906,\n",
       " 0.011250612387921799,\n",
       " 0.8669832803579107,\n",
       " 0.0855074044346874,\n",
       " 0.5847537938948407,\n",
       " 0.06276878790797313,\n",
       " 0.5395331900825824,\n",
       " 0.8906566455277346,\n",
       " 0.2807687872573008,\n",
       " 0.39719546564098274,\n",
       " 0.02966436252712812,\n",
       " 0.44287565785038696,\n",
       " 0.31301958004418406,\n",
       " 0.7397880689035601,\n",
       " 0.7605933951788421,\n",
       " 0.47514382014784284,\n",
       " 0.6945981278050383,\n",
       " 0.012050447286709454,\n",
       " 0.03969248090726696,\n",
       " 0.02846911868017432,\n",
       " 0.7446035867496101,\n",
       " 0.5624436455495219,\n",
       " 0.34085316971992663,\n",
       " 0.9616829114981377,\n",
       " 0.09383445368395316,\n",
       " 0.8644795258564173,\n",
       " 0.13742809816689516,\n",
       " 0.28965052351586673,\n",
       " 0.9627462493482296,\n",
       " 0.9458711754533118,\n",
       " 0.2468440692520234,\n",
       " 0.9152463465062566,\n",
       " 0.8887034744184267,\n",
       " 0.6852477306895984,\n",
       " 0.07528464816644553,\n",
       " 0.07098823667918486,\n",
       " 0.9600272051523518,\n",
       " 0.8311098728645788,\n",
       " 0.816490512247829,\n",
       " 0.0617407327571039,\n",
       " 0.4964987315221808,\n",
       " 0.8068753023192557,\n",
       " 0.5160410812917615,\n",
       " 0.5526915321287303,\n",
       " 0.14335594680531938,\n",
       " 0.4054203500127659,\n",
       " 0.725352108542078,\n",
       " 0.8315012078994488,\n",
       " 0.27581119147411004,\n",
       " 0.5738097115498458,\n",
       " 0.28074355569547105,\n",
       " 0.7262975037142254,\n",
       " 0.6465805256560061,\n",
       " 0.3464854860296439,\n",
       " 0.06572460978568972,\n",
       " 0.5135556766765785,\n",
       " 0.9850101654905202,\n",
       " 0.27421613714094173,\n",
       " 0.08981777296587001,\n",
       " 0.30973285966542063,\n",
       " 0.41693001167555443,\n",
       " 0.9384904558223565,\n",
       " 0.656348448288781,\n",
       " 0.8190446829331118,\n",
       " 0.38792372123823804,\n",
       " 0.8379362250085518,\n",
       " 0.8398125291430265,\n",
       " 0.7417441363359737,\n",
       " 0.3575162773650541,\n",
       " 0.8231537190792747,\n",
       " 0.4279227182158236,\n",
       " 0.44937107661534204,\n",
       " 0.29618350374974467,\n",
       " 0.08272819144169108,\n",
       " 0.24182703835670982,\n",
       " 0.27729933959776143,\n",
       " 0.8969663628221655,\n",
       " 0.2787415159597645,\n",
       " 0.6776954853359488,\n",
       " 0.5028656973237912,\n",
       " 0.028244224256174344,\n",
       " 0.11568737800697804,\n",
       " 0.9616232366354136,\n",
       " 0.4439672821093763,\n",
       " 0.5488019035600343,\n",
       " 0.7149311524643777,\n",
       " 0.4762812080850346,\n",
       " 0.9054175911374885,\n",
       " 0.6978959148148999,\n",
       " 0.6018847170608761,\n",
       " 0.801788968689247,\n",
       " 0.8689028191342096,\n",
       " 0.5342968621769967,\n",
       " 0.3073163564365494,\n",
       " 0.5738208972468132,\n",
       " 0.6175498970296953,\n",
       " 0.6280459894641055,\n",
       " 0.45264944762698567,\n",
       " 0.8886579425458364,\n",
       " 0.549491601585904,\n",
       " 0.17100267431164073,\n",
       " 0.234302842845159,\n",
       " 0.41485716002546846,\n",
       " 0.2670769750889902,\n",
       " 0.8083061262273812,\n",
       " 0.5479861133581791,\n",
       " 0.35056545160508046,\n",
       " 0.7473005441425697,\n",
       " 0.8707702686791408,\n",
       " 0.8310289538945135,\n",
       " 0.6282282818789753,\n",
       " 0.14067792497935283,\n",
       " 0.963823307246057,\n",
       " 0.2672456725716137,\n",
       " 0.36191150911966086,\n",
       " 0.41666928209361187,\n",
       " 0.8724431719305146,\n",
       " 0.05012132601279251,\n",
       " 0.674612047447244,\n",
       " 0.5418483893203009,\n",
       " 0.22268301499019993,\n",
       " 0.6110468577019197,\n",
       " 0.19363087660738898,\n",
       " 0.8924441480073928,\n",
       " 0.19497572346854608,\n",
       " 0.13648553387619855,\n",
       " 0.11771187265755612,\n",
       " 0.9713202895089654,\n",
       " 0.8931860796130702,\n",
       " 0.743407255674412,\n",
       " 0.7801875408654246,\n",
       " 0.35711754340078683,\n",
       " 0.14868455668420888,\n",
       " 0.6739914978069023,\n",
       " 0.5101637130321944,\n",
       " 0.6447794970204122,\n",
       " 0.7710508134001944,\n",
       " 0.9968688200216159,\n",
       " 0.562285281077412,\n",
       " 0.1069282709013758,\n",
       " 0.5548561022251741,\n",
       " 0.7898385695346146,\n",
       " 0.7411277551659035,\n",
       " 0.23409896417616205,\n",
       " 0.32770637418706816,\n",
       " 0.9410503496593186,\n",
       " 0.395846114757608,\n",
       " 0.174233508766776,\n",
       " 0.13915327393062993,\n",
       " 0.9361667977505346,\n",
       " 0.9134135602532318,\n",
       " 0.43636629168994145,\n",
       " 0.1873608874604853,\n",
       " 0.8035859536614749,\n",
       " 0.37792959730015996,\n",
       " 0.10342181589877464,\n",
       " 0.513399167032216,\n",
       " 0.9434164794951099,\n",
       " 0.9816816100501325,\n",
       " 0.5745020462405084,\n",
       " 0.5031478552191248,\n",
       " 0.8263201687806518,\n",
       " 0.8028077753351782,\n",
       " 0.8898201700224805,\n",
       " 0.3631941104961893,\n",
       " 0.29123803694044936,\n",
       " 0.2519721699963916,\n",
       " 0.38717371417722835,\n",
       " 0.8229303895796455,\n",
       " 0.0615563204093893,\n",
       " 0.39009460165668164,\n",
       " 0.030389169188324128,\n",
       " 0.9917025420983727,\n",
       " 0.5204683995147575,\n",
       " 0.9257510259163776,\n",
       " 0.9647088274085199,\n",
       " 0.8918124492043982,\n",
       " 0.21067808037195734,\n",
       " 0.3623527585303489,\n",
       " 0.3604139485222756,\n",
       " 0.3520198223069979,\n",
       " 0.023113687078285317,\n",
       " 0.4263005335077369,\n",
       " 0.42400144931089845,\n",
       " 0.12773066699382896,\n",
       " 0.12474549260669754,\n",
       " 0.03884719989199226,\n",
       " 0.24891038697730317,\n",
       " 0.4649396188988525,\n",
       " 0.4450541330552168,\n",
       " 0.5361487758599505,\n",
       " 0.902105728750461,\n",
       " 0.5386679460737889,\n",
       " 0.5908274256665752,\n",
       " 0.07169581495361022,\n",
       " 0.868792837649872,\n",
       " 0.3490974150073167,\n",
       " 0.6041188692024477,\n",
       " 0.7303441531192264,\n",
       " 0.48881260688872286,\n",
       " 0.9636937301479255,\n",
       " 0.553974565766072,\n",
       " 0.019007866008166063,\n",
       " 0.2579579493055085,\n",
       " 0.021366962308552173,\n",
       " 0.46797586317107853,\n",
       " 0.6501527881420982,\n",
       " 0.8303442147520775,\n",
       " 0.4451221588907853,\n",
       " 0.7894463528118204,\n",
       " 0.8225682010879196,\n",
       " 0.09392749573686843,\n",
       " 0.7157752872392137,\n",
       " 0.6364426471634034,\n",
       " 0.6728493333145869,\n",
       " 0.8714215145792638,\n",
       " 0.25647049427134805,\n",
       " 0.2790650147118524,\n",
       " 0.7083352728069395,\n",
       " 0.7058597914235322,\n",
       " 0.574151769485515,\n",
       " 0.462008279672958,\n",
       " 0.3032726605043956,\n",
       " 0.1335840814098751,\n",
       " 0.8525715338011969,\n",
       " 0.5371836136074576,\n",
       " 0.4578677183867793,\n",
       " 0.7989959931566791,\n",
       " 0.20773012273795388,\n",
       " 0.5321665271156593,\n",
       " 0.8393334180236494,\n",
       " 0.7898647084403059,\n",
       " 0.9131688599096531,\n",
       " 0.30131494439119,\n",
       " 0.6642293976152959,\n",
       " 0.7277125666712894,\n",
       " 0.3550952538778852,\n",
       " 0.9981032672317416,\n",
       " 0.715686101928386,\n",
       " 0.8433072826864426,\n",
       " 0.3466684080416714,\n",
       " 0.4317812808074969,\n",
       " 0.5195143770825414,\n",
       " 0.8294332604720835,\n",
       " 0.2100227931852986,\n",
       " 0.36210138124815605,\n",
       " 0.6298548289605844,\n",
       " 0.2081518139178884,\n",
       " 0.3808884420335138,\n",
       " 0.10838678956072456,\n",
       " 0.6667075363861447,\n",
       " 0.6098883530017069,\n",
       " 0.8698427724987134,\n",
       " 0.11863817602477156,\n",
       " 0.27128047799042676,\n",
       " 0.834515747357181,\n",
       " 0.18166393648934198,\n",
       " 0.002190958016638933,\n",
       " 0.08059697146964451,\n",
       " 0.9032489741422457,\n",
       " 0.7939250763763085,\n",
       " 0.24181190079576098,\n",
       " 0.8991575519923695,\n",
       " 0.702300635643712,\n",
       " 0.9719995839327923,\n",
       " 0.5416935744110281,\n",
       " 0.3296140838331999,\n",
       " 0.5716194917649658,\n",
       " 0.28788683454240105,\n",
       " 0.7434287377385863,\n",
       " 0.4945579481777421,\n",
       " 0.7372054942486688,\n",
       " 0.8496141523629807,\n",
       " 0.622626634350584,\n",
       " 0.5589898700654169,\n",
       " 0.8246929815390653,\n",
       " 0.12284210758209146,\n",
       " 0.16842644449824828,\n",
       " 0.7070801705959748,\n",
       " 0.355524086482761,\n",
       " 0.43465954092496495,\n",
       " 0.9146075837069917,\n",
       " 0.14140573507841858,\n",
       " 0.21760896069502245,\n",
       " 0.9034379544572996,\n",
       " 0.39090316013929394,\n",
       " 0.9352432355463943,\n",
       " 0.13737515714580484,\n",
       " 0.6022290671622733,\n",
       " 0.5900738202679975,\n",
       " 0.3754838842343816,\n",
       " 0.2958771236790041,\n",
       " 0.6640428973902501,\n",
       " 0.8198877906062194,\n",
       " 0.6241445992028286,\n",
       " 0.8023624892125307,\n",
       " 0.7763269894210517,\n",
       " 0.1786240599692681,\n",
       " 0.7948653387335998,\n",
       " 0.4886602313925744,\n",
       " 0.1744177415820657,\n",
       " 0.3806506806014214,\n",
       " 0.13631554500601295,\n",
       " 0.2630007427159079,\n",
       " 0.6494721667938651,\n",
       " 0.8062482098074746,\n",
       " 0.34971668594065464,\n",
       " 0.027545399523245306,\n",
       " 0.44279084823810855,\n",
       " 0.5416582307469329,\n",
       " 0.9678250241441799,\n",
       " 0.8080598909687426,\n",
       " 0.6657861886226546,\n",
       " 0.4803785388880617,\n",
       " 0.8079453459286958,\n",
       " 0.8489936097448662,\n",
       " 0.8394591605049109,\n",
       " 0.8113142275721076,\n",
       " 0.34610176055799136,\n",
       " 0.8848198531719716,\n",
       " 0.8315508455308014,\n",
       " 0.4569224127509858,\n",
       " 0.5182301183525589,\n",
       " 0.2781276599959801,\n",
       " 0.4471896132528962,\n",
       " 0.47983834006294235,\n",
       " 0.49861809616533026,\n",
       " 0.17871384535564472,\n",
       " 0.29975703986355673,\n",
       " 0.17955554779051675,\n",
       " 0.712150213707034,\n",
       " 0.8095703039792292,\n",
       " 0.40453294058858236,\n",
       " 0.07359768050578341,\n",
       " 0.9757579761182483,\n",
       " 0.9214865294260018,\n",
       " 0.6102048255562443,\n",
       " 0.1403746972722406,\n",
       " 0.9439465733455706,\n",
       " 0.7681691397005446,\n",
       " 0.22521054782022543,\n",
       " 0.43387461874513,\n",
       " 0.6974398307128559,\n",
       " 0.6360941750360367,\n",
       " 0.9771079270356421,\n",
       " 0.6735844190946351,\n",
       " 0.80505287903985,\n",
       " 0.7004317066639417,\n",
       " 0.5830713236619723,\n",
       " 0.813456723594871,\n",
       " 0.5567758740850548,\n",
       " 0.9235206395602442,\n",
       " 0.4914058897296162,\n",
       " 0.25353057337786966,\n",
       " 0.5429953751131859,\n",
       " 0.7889105741108501,\n",
       " 0.41243388578312823,\n",
       " 0.06798573593415524,\n",
       " 0.7397484726711658,\n",
       " 0.01350531007551381,\n",
       " 0.708276518992239,\n",
       " 0.05848240161703877,\n",
       " 0.9336501017215316,\n",
       " 0.37294574702407113,\n",
       " 0.038760888237945545,\n",
       " 0.5312314690856007,\n",
       " 0.8697866436597219,\n",
       " 0.9449688301719903,\n",
       " 0.18924990362092453,\n",
       " 0.05293881197586747,\n",
       " 0.49594211095803853,\n",
       " 0.3532736875940595,\n",
       " 0.39103613994501596,\n",
       " 0.1394721063793235,\n",
       " 0.6473147719874834,\n",
       " 0.23377903740144423,\n",
       " 0.4812451161855753,\n",
       " 0.5595764507426744,\n",
       " 0.035683557755672,\n",
       " 0.7389499996917211,\n",
       " 0.25305052760166435,\n",
       " 0.41509105473472363,\n",
       " 0.3980615962180025,\n",
       " 0.6678906489714688,\n",
       " 0.337907875145552,\n",
       " 0.9079167941141528,\n",
       " 0.5533099266405509,\n",
       " 0.4865788505813178,\n",
       " 0.8396101572387152,\n",
       " 0.6995626731862853,\n",
       " 0.6581732630114687,\n",
       " 0.6691114947298341,\n",
       " 0.18002326564340854,\n",
       " 0.4779303099416202,\n",
       " 0.6172710105087603,\n",
       " 0.25398972477914616,\n",
       " 0.44304994610107307,\n",
       " 0.57017660201329,\n",
       " 0.5402550276852647,\n",
       " 0.12555227179492334,\n",
       " 0.9497846418154499,\n",
       " 0.9115529648169062,\n",
       " 0.10994368611198624,\n",
       " 0.33674385169273446,\n",
       " 0.768886287374123,\n",
       " 0.8946747563261648,\n",
       " 0.40692819431552607,\n",
       " 0.35243528668996305,\n",
       " 0.05011411477362859,\n",
       " 0.3629763480255198,\n",
       " 0.16122992121858826,\n",
       " 0.9242953367771742,\n",
       " 0.05160070825037344,\n",
       " 0.294641157183986,\n",
       " 0.1742096969632866,\n",
       " 0.7602455976353475,\n",
       " 0.6793210970521012,\n",
       " 0.5851508285750578,\n",
       " 0.5527903035919521,\n",
       " 0.555481759322437,\n",
       " 0.7930328536544288,\n",
       " 0.31382004963190857,\n",
       " 0.6129567611871556,\n",
       " 0.24237674325887637,\n",
       " 0.3252345911444773,\n",
       " 0.4666014827197599,\n",
       " 0.6467895612530219,\n",
       " 0.8971678273355298,\n",
       " 0.8752010870403608,\n",
       " 0.35368036069726094,\n",
       " 0.23943287300431781,\n",
       " 0.07101950039130212,\n",
       " 0.36535272604698255,\n",
       " 0.8795402846404996,\n",
       " 0.5683853919639535,\n",
       " 0.7647730103365401,\n",
       " 0.08890819331422561,\n",
       " 0.4741717863111963,\n",
       " 0.47324545581211763,\n",
       " 0.4825200062691086,\n",
       " 0.9858658740630846,\n",
       " 0.3963659790802416,\n",
       " 0.5319881676883526,\n",
       " 0.5649145749148397,\n",
       " 0.9154089792480059,\n",
       " 0.34667642883986094,\n",
       " 0.6159857617876732,\n",
       " 0.06586918293819177,\n",
       " 0.9303128702675755,\n",
       " 0.5297291013252255,\n",
       " 0.015902060919460004,\n",
       " 0.20643587691930954,\n",
       " 0.5886409069191537,\n",
       " 0.6527667718723341,\n",
       " 0.8304975033754919,\n",
       " 0.320262463575405,\n",
       " 0.907225978829686,\n",
       " 0.7341935391299783,\n",
       " 0.7512327636871329,\n",
       " 0.69635225326693,\n",
       " 0.6146064133983477,\n",
       " 0.49995485304765896,\n",
       " 0.9284740324249472,\n",
       " 0.9562255976380639,\n",
       " 0.38174057469882594,\n",
       " 0.6263705801650036,\n",
       " 0.9640708688037072,\n",
       " 0.26341982996105173,\n",
       " 0.2607977594769645,\n",
       " 0.9107038469837971,\n",
       " 0.42445096799326154,\n",
       " 0.9417580277104194,\n",
       " 0.7136633671283654,\n",
       " 0.807676741547206,\n",
       " 0.4708016071216854,\n",
       " 0.40039152353463614,\n",
       " 0.8760463425848605,\n",
       " 0.5077309800434346,\n",
       " 0.7547009782050912,\n",
       " 0.1560434553790987,\n",
       " 0.8300021076095816,\n",
       " 0.30812372572476165,\n",
       " 0.3176912064100551,\n",
       " 0.49138068408957414,\n",
       " 0.8133108468402964,\n",
       " 0.5888573680214577,\n",
       " 0.8241661037381749,\n",
       " 0.6370599644184284,\n",
       " 0.4593625331887542,\n",
       " 0.043362832519713845,\n",
       " 0.10698173582455084,\n",
       " 0.5197795517458719,\n",
       " 0.02469501269566332,\n",
       " 0.49719625621496544,\n",
       " 0.5194047311811162,\n",
       " 0.25430290372483044,\n",
       " 0.6925234060672524,\n",
       " 0.7232396020032907,\n",
       " 0.8353356486443725,\n",
       " 0.005559717577074075,\n",
       " 0.7666758612301349,\n",
       " 0.16377668995111816,\n",
       " 0.5778078259825312,\n",
       " 0.84292797916169,\n",
       " 0.45510146438131016,\n",
       " 0.9768415359284878,\n",
       " 0.3452291605960054,\n",
       " 0.24348629354899842,\n",
       " 0.21644789937744957,\n",
       " 0.8404032627485332,\n",
       " 0.7681476063198486,\n",
       " 0.6441514080051345,\n",
       " 0.2861052276605526,\n",
       " 0.04775506496528459,\n",
       " 0.12629771695497305,\n",
       " 0.5811549875071264,\n",
       " 0.962374960316415,\n",
       " 0.056324067318374915,\n",
       " 0.18502007029356393,\n",
       " 0.02958686539518096,\n",
       " 0.42168416222410054,\n",
       " 0.024402112882132898,\n",
       " 0.11013594915611613,\n",
       " 0.10538305967527883,\n",
       " 0.8135919054215177,\n",
       " 0.5729112741374662,\n",
       " 0.033671920628718155,\n",
       " 0.726928646813212,\n",
       " 0.7211619048246769,\n",
       " 0.2340313747188688,\n",
       " 0.6671691382386645,\n",
       " 0.7972363101430019,\n",
       " 0.8057265975369642,\n",
       " 0.25542385474295914,\n",
       " 0.03761486489273058,\n",
       " 0.7256117829845832,\n",
       " 0.6738606273515313,\n",
       " 0.07682638139808862,\n",
       " 0.2254314165179777,\n",
       " 0.9919828653359885,\n",
       " 0.1457787215795433,\n",
       " 0.2572811758987241,\n",
       " 0.04461418666941719,\n",
       " 0.7180126431532604,\n",
       " 0.7749988548962218,\n",
       " 0.3716554973159931,\n",
       " 0.029070921060345034,\n",
       " 0.13154567588264598,\n",
       " 0.7996139227503167,\n",
       " 0.2169168870507756,\n",
       " 0.2080029557474038,\n",
       " 0.7846086706576669,\n",
       " 0.49016269078436014,\n",
       " 0.020725618998932327,\n",
       " 0.6039045165258248,\n",
       " 0.478647052576051,\n",
       " 0.6013892463733506,\n",
       " 0.5938161266569708,\n",
       " 0.8218707171389875,\n",
       " 0.9707854014041412,\n",
       " 0.37057165709377726,\n",
       " 0.26898125575241516,\n",
       " 0.22795122479259156,\n",
       " 0.4031733839561138,\n",
       " 0.620435499128013,\n",
       " 0.46815126466374457,\n",
       " 0.5119095471115148,\n",
       " 0.24238663484746903,\n",
       " 0.20667277596220934,\n",
       " 0.20389683820525484,\n",
       " 0.51645749388994,\n",
       " 0.178618305954112,\n",
       " 0.8224136604957486,\n",
       " 0.18552614324118055,\n",
       " 0.4208146179032972,\n",
       " 0.5987042416751581,\n",
       " 0.24646163687330436,\n",
       " 0.948223613671362,\n",
       " 0.7526256581552839,\n",
       " 0.032877790102550764,\n",
       " 0.5490959878669118,\n",
       " 0.017952947545933795,\n",
       " 0.4435297960455654,\n",
       " 0.3481060942933625,\n",
       " 0.28532994509124343,\n",
       " 0.8857562923821457,\n",
       " 0.8194162939439171,\n",
       " 0.24870313486514528,\n",
       " 0.5383892574818493,\n",
       " 0.5656544922447279,\n",
       " 0.17825776676082394,\n",
       " 0.43390324650315615,\n",
       " 0.7397489947624885,\n",
       " 0.7463263831608624,\n",
       " 0.48784781287225343,\n",
       " 0.9576222803245661,\n",
       " 0.6309164146480767,\n",
       " 0.8604522680856487,\n",
       " 0.917635934862213,\n",
       " 0.6858776888976622,\n",
       " 0.6203397821911869,\n",
       " 0.9136810342656685,\n",
       " 0.43570940760667487,\n",
       " 0.4499893434400325,\n",
       " 0.2566802456208773,\n",
       " 0.8905629324241272,\n",
       " 0.947051787550548,\n",
       " 0.87031573781578,\n",
       " 0.559995847545726,\n",
       " 0.2972371825384875,\n",
       " 0.42532340028322235,\n",
       " 0.672421028174731,\n",
       " 0.5222299309359238,\n",
       " 0.5767228956171184,\n",
       " 0.1815102532703261,\n",
       " 0.24829213396610672,\n",
       " 0.244256185462565,\n",
       " 0.07037676796107795,\n",
       " 0.3563334935093708,\n",
       " 0.31832708052683245,\n",
       " 0.18698320744300567,\n",
       " 0.2020647477533638,\n",
       " 0.6851040381655065,\n",
       " 0.28756086479208887,\n",
       " 0.22377624023148357,\n",
       " 0.8531472555154331,\n",
       " 0.22300355029962904,\n",
       " 0.2749441525397248,\n",
       " 0.36502540613527956,\n",
       " 0.048534349484675166,\n",
       " 0.9639926880269257,\n",
       " 0.9854306282245203,\n",
       " 0.09266980088499899,\n",
       " 0.9097419112722069,\n",
       " 0.523796562561347,\n",
       " 0.9685045273370535,\n",
       " 0.0058896744606699025,\n",
       " 0.13064291137609518,\n",
       " 0.9356895958594648,\n",
       " 0.9455728848657393,\n",
       " 0.36347877603553824,\n",
       " 0.7855069873759989,\n",
       " 0.4172085464041755,\n",
       " 0.13532720379210117,\n",
       " 0.47250039001688027,\n",
       " 0.23731301368938007,\n",
       " 0.0013054097776188378,\n",
       " 0.6813678627120587,\n",
       " 0.8206146039813432,\n",
       " 0.31079654395322276,\n",
       " 0.5178255726251897,\n",
       " 0.04346700727551156,\n",
       " 0.7804902592324852,\n",
       " 0.6867960183741821,\n",
       " 0.9249523526703007,\n",
       " 0.9792207426017954,\n",
       " 0.2047247993975364,\n",
       " 0.8764478599321337,\n",
       " 0.4070671566269751,\n",
       " 0.7957406492128187,\n",
       " 0.9315290940230821,\n",
       " 0.19842760070511856,\n",
       " 0.9004766753298549,\n",
       " 0.5267861168116112,\n",
       " 0.41324694840054976,\n",
       " 0.09971730552225144,\n",
       " 0.07069256088991416,\n",
       " 0.7434974983501829,\n",
       " 0.7501599637408729,\n",
       " 0.2050504463090358,\n",
       " 0.37868237046172737,\n",
       " 0.5942157545501184,\n",
       " 0.9049862292675797,\n",
       " 0.4193910396873164,\n",
       " 0.03259111553965732,\n",
       " 0.9266958036686558,\n",
       " 0.6207696865406076,\n",
       " 0.6142590320663714,\n",
       " 0.9937439301984808,\n",
       " 0.5520869778389279,\n",
       " 0.22378932847581567,\n",
       " 0.9248690021205798,\n",
       " 0.836314058341322,\n",
       " 0.8143351503223104,\n",
       " 0.42154330798583417,\n",
       " 0.9674579412657639,\n",
       " 0.6176467161948661,\n",
       " 0.45746777372193526,\n",
       " 0.2590098268085339,\n",
       " 0.5429463429264418,\n",
       " 0.9810031682323155,\n",
       " 0.926448410448836,\n",
       " 0.09353097658904086,\n",
       " 0.0833879820028427,\n",
       " 0.8741147700665872,\n",
       " 0.7717192233229236,\n",
       " 0.10401349531368986,\n",
       " 0.31188745867726,\n",
       " 0.9306880919200122,\n",
       " 0.4710425211018824,\n",
       " 0.9155389849817468,\n",
       " 0.8287016423600108,\n",
       " 0.9787831297136186,\n",
       " 0.9543090848928152,\n",
       " 0.06684319589752175,\n",
       " 0.6335097826377859,\n",
       " 0.34044034956655755,\n",
       " 0.19575796857718042,\n",
       " 0.1860250843781205,\n",
       " 0.4571043957432789,\n",
       " 0.8588472702146178,\n",
       " 0.33755586110869484,\n",
       " 0.8850412616130116,\n",
       " 0.829019159178611,\n",
       " 0.2585517602926657,\n",
       " 0.9844822498434171,\n",
       " 0.8985354568740348,\n",
       " 0.9408527196112421,\n",
       " 0.9084038421187222,\n",
       " 0.466478004974178,\n",
       " 0.9959989233988652,\n",
       " 0.00585990247717727,\n",
       " 0.3412503600371445,\n",
       " 0.45309364585702194,\n",
       " 0.5599165612098864,\n",
       " 0.7431426270719147,\n",
       " 0.6707722813794422,\n",
       " 0.3203452058895806,\n",
       " ...]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_digits = []\n",
    "new_data =[]\n",
    "for f in range(1,1000):\n",
    "    for k in range(1,784):\n",
    "        new_digit = np.random.rand()\n",
    "        new_digits.append(new_digit)\n",
    "    new_data.append(new_digits)\n",
    "    \n",
    "new_data[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7196117   0.80863738  0.91138152 ...,  0.27136539  0.01646662\n",
      "   0.71419671]\n",
      " [ 0.99390438  0.68330645  0.75467853 ...,  0.61747799  0.76719202\n",
      "   0.88481796]]\n"
     ]
    }
   ],
   "source": [
    "noise = np.random.uniform(mini_train_data)\n",
    "print noise[1:3,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(11) Remember that a strongly calibrated classifier is rougly 90% accurate when the posterior probability of the predicted class is 0.9. A weakly calibrated classifier is more accurate when the posterior is 90% than when it is 80%. A poorly calibrated classifier has no positive correlation between posterior and accuracy.\n",
    "\n",
    "Train a BernoulliNB model with a reasonable alpha value. For each posterior bucket (think of a bin in a histogram), you want to estimate the classifier's accuracy. So for each prediction, find the bucket the maximum posterior belongs to and update the \"correct\" and \"total\" counters.\n",
    "\n",
    "How would you characterize the calibration for the Naive Bayes model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def P11(buckets, correct, total):\n",
    "    \n",
    "### STUDENT START ###\n",
    "\n",
    "\n",
    "                \n",
    "### STUDENT END ###\n",
    "\n",
    "#buckets = [0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0]\n",
    "#correct = [0 for i in buckets]\n",
    "#total = [0 for i in buckets]\n",
    "\n",
    "#P11(buckets, correct, total)\n",
    "\n",
    "#for i in range(len(buckets)):\n",
    "#    accuracy = 0.0\n",
    "#    if (total[i] > 0): accuracy = correct[i] / total[i]\n",
    "#    print 'p(pred) <= %.13f    total = %3d    accuracy = %.3f' %(buckets[i], total[i], accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(12) EXTRA CREDIT\n",
    "\n",
    "Try designing extra features to see if you can improve the performance of Naive Bayes on the dev set. Here are a few ideas to get you started:\n",
    "- Try summing the pixel values in each row and each column.\n",
    "- Try counting the number of enclosed regions; 8 usually has 2 enclosed regions, 9 usually has 1, and 7 usually has 0.\n",
    "\n",
    "Make sure you comment your code well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def P12():\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P12()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
